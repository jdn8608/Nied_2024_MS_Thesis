{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca03d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 10:52:05.675100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib notebook \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import h5py as h5\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93e8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbf33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Activation, SeparableConv2D, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K # Losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27e821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, cuda\n",
    "from timeit import default_timer as timer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934d8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c53a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c4aeb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "1:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2:  True\n",
      "3:  /device:GPU:0\n",
      "4:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num CPUs Available:  1\n",
      "Num GPUs Available:  1\n",
      "Available GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 10:52:17.121224: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-19 10:52:17.121407: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-06-19 10:52:18.043820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:82:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2024-06-19 10:52:18.043900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-06-19 10:52:18.225331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-06-19 10:52:18.225432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-06-19 10:52:18.347316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-19 10:52:18.502126: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-19 10:52:18.590539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-19 10:52:18.685412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-06-19 10:52:18.867270: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-06-19 10:52:18.872581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-06-19 10:52:18.873896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 10:52:18.877454: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-19 10:52:18.880058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:82:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2024-06-19 10:52:18.880134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-06-19 10:52:18.880187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-06-19 10:52:18.880236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-06-19 10:52:18.880282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-19 10:52:18.880329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-19 10:52:18.880375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-19 10:52:18.880421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-06-19 10:52:18.880468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-06-19 10:52:18.885393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-06-19 10:52:18.885492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-06-19 10:52:21.356687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-19 10:52:21.356753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-06-19 10:52:21.356770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-06-19 10:52:21.361717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 22475 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:82:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print('1: ', tf.config.list_physical_devices('GPU'))\n",
    "print('2: ', tf.test.is_built_with_cuda())\n",
    "print('3: ', tf.test.gpu_device_name())\n",
    "print('4: ', tf.config.get_visible_devices())\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Available GPUs: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0202ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51946fb9",
   "metadata": {},
   "source": [
    "# Evaluate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf4ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data/keeling/a/jdnied2/a/MODIS_ML/data/output/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1f8177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "labels_dir = '/data/keeling/a/jdnied2/c/ML/MOD-CM-NN/data/labels/labels_v03.csv'\n",
    "temp = pd.read_csv(f'{labels_dir}', sep=',',index_col=False)\n",
    "uniqued_frame = temp.drop_duplicates(subset='Filename', keep='last')\n",
    "np_uniq = np.array(uniqued_frame)\n",
    "print(len(uniqued_frame))\n",
    "indices = np.where(uniqued_frame['Label']>=3)\n",
    "print(len(indices[0]))\n",
    "indices_good = np.where(uniqued_frame['Label']>=3)\n",
    "indices_bad = np.where(uniqued_frame['Label']<3)\n",
    "\n",
    "\n",
    "\n",
    "training_labels = np_uniq[indices]\n",
    "# training_labels = np_uniq\n",
    "print(len(training_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a9c6b",
   "metadata": {},
   "source": [
    "# LOAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb29432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_012',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_025',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011169.1425_.hdf+Image_000',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_104',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_146',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_113',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_047',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011073.1430_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010230.1425_.hdf+Image_005',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010230.1425_.hdf+Image_011',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010230.1425_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010230.1425_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_160',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_068',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_152',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_020',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_063',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1430_.hdf+Image_126',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_078',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_086',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_053',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_028',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_070',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005104.1435_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_054',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_182',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_133',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_100',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004230.1430_.hdf+Image_141',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_035',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_112',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_148',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_094',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_108',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017265.1430_.hdf+Image_026',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003339.1435_.hdf+Image_074',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003339.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003339.1435_.hdf+Image_142',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003339.1435_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003339.1435_.hdf+Image_122',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_089',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_138',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_051',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_094',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_028',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_112',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_046',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_162',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014353.1430_.hdf+Image_058',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_041',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_108',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_072',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_103',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_047',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017057.1435_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_167',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_104',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_092',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_132',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_174',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015260.1430_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005360.1425_.hdf+Image_032',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_082',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_086',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_037',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_026',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_070',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012300.1435_.hdf+Image_046',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_043',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_104',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_046',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018332.1430_.hdf+Image_002',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018332.1430_.hdf+Image_030',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018332.1430_.hdf+Image_165',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_091',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_111',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_063',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_057',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_034',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_086',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013174.1435_.hdf+Image_114',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_032',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_131',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_104',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_093',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2015212.1435_.hdf+Image_066',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_157',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_129',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_158',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_156',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_180',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017361.1430_.hdf+Image_011',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_035',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_057',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_061',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_001',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003195.1435_.hdf+Image_000',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_070',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_085',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_146',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_001',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_159',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_119',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018236.1435_.hdf+Image_076',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_074',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_103',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_086',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_018',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_003',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_014',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_010',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_018',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012156.1425_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_134',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_043',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_048',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_044',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_059',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_041',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_112',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_096',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016199.1435_.hdf+Image_011',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_149',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_088',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_129',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_183',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_009',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013046.1430_.hdf+Image_056',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_124',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_115',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_092',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_095',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011153.1430_.hdf+Image_106',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_103',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_136',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_179',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_105',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_120',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_183',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_125',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005344.1430_.hdf+Image_177',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_084',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_104',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_102',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_056',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_071',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017329.1435_.hdf+Image_080',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004262.1425_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004262.1425_.hdf+Image_014',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010134.1435_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_101',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_064',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_076',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_033',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003179.1435_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010150.1435_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010150.1435_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010150.1435_.hdf+Image_001',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005232.1430_.hdf+Image_162',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005232.1430_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005232.1430_.hdf+Image_132',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011041.1425_.hdf+Image_033',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011041.1425_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011041.1425_.hdf+Image_026',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011041.1425_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_037',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_168',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_114',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_049',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_060',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_097',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_044',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_108',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010166.1435_.hdf+Image_028',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_005',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_020',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_009',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_014',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_004',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2013318.1425_.hdf+Image_010',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_003',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_000',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_012',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_005',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_009',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004086.1425_.hdf+Image_014',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009211.1430_.hdf+Image_068',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009211.1430_.hdf+Image_026',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009211.1430_.hdf+Image_081',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_044',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_071',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_041',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_066',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_023',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_049',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011089.1435_.hdf+Image_042',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_116',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_118',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_088',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_093',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_072',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_136',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016135.1435_.hdf+Image_073',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_022',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_090',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_034',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_088',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_137',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_106',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_116',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_101',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_114',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_043',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_003',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_066',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_038',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_090',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_119',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_047',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_124',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_006',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_050',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_041',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_129',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_097',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016007.1435_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_092',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_091',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_085',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_064',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_057',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_063',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_042',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_108',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_102',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_068',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010054.1435_.hdf+Image_000',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_138',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_158',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_009',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_179',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_126',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_034',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_063',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_115',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_041',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_046',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_134',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_163',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011297.1430_.hdf+Image_120',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_085',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_090',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_042',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_051',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_056',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_060',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_088',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_059',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_025',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016327.1435_.hdf+Image_111',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005152.1425_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005152.1425_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005152.1425_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_103',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_071',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_004',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_012',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_057',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_029',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_096',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_022',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_066',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_054',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_033',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2018364.1435_.hdf+Image_023',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009339.1430_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_110',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_076',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_109',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_073',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_097',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_123',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_115',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_092',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_062',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006139.1430_.hdf+Image_108',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_102',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_028',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_050',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_006',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_097',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005216.1430_.hdf+Image_079',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_120',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_061',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_046',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_123',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_176',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_134',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_135',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_026',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_140',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_182',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_031',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_112',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_072',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2011249.1430_.hdf+Image_107',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_170',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_050',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_052',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_143',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_086',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_005',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_049',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_141',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_183',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2004054.1430_.hdf+Image_140',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_002',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_103',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_073',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_063',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_001',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_070',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_011',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009259.1435_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_092',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_037',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_044',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_015',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_089',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_030',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_055',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_021',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_032',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_062',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_033',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014065.1435_.hdf+Image_088',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_054',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_056',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_003',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_131',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_017',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_107',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_061',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2006123.1430_.hdf+Image_123',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_000',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_018',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_036',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_040',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_028',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_004',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_051',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_042',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_072',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_029',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_016',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012332.1435_.hdf+Image_048',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012124.1435_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012124.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2012124.1435_.hdf+Image_053',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2009227.1435_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005072.1430_.hdf+Image_130',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005072.1430_.hdf+Image_085',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_117',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_136',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_065',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_176',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2017121.1430_.hdf+Image_119',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_062',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_145',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_160',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_130',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010006.1430_.hdf+Image_012',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_005',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2014097.1435_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_067',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_128',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_091',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_097',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2016311.1430_.hdf+Image_011',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_032',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_033',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_043',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_126',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_172',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_083',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_037',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_118',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2010070.1430_.hdf+Image_183',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_018',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_039',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_027',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_035',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_071',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_054',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_014',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_019',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_013',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_003',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_075',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005328.1435_.hdf+Image_062',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005120.1435_.hdf+Image_025',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2005120.1435_.hdf+Image_024',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_007',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_060',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_087',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_106',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_008',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_056',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_093',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_050',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_049',\n",
       " '/data/keeling/a/jdnied2/a/MODIS_ML/data/output/MODIS_MLData_Shape_64x64_2003067.1435_.hdf+Image_016']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_files = []\n",
    "for tr in training_labels:\n",
    "    use_files.append(tr[0])\n",
    "use_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22ea6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bands_to_use(bands_array):\n",
    "    return [f'Band_{b}.0' for b in bands_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e47487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modis_data(bands_to_use, files):\n",
    "    bands = format_bands_to_use(bands_to_use)\n",
    "#     bands.append('Longitude')\n",
    "#     bands.append('Latitude')\n",
    "    print(bands)\n",
    "    \n",
    "    rad_images = np.zeros((len(files),len(bands),64,64),dtype=np.float32)\n",
    "    mask_images = np.zeros((len(files),64,64),dtype=np.float32)\n",
    "    data_index = 0\n",
    "\n",
    "    for line in tqdm(files):\n",
    "        l_split = line.split('+')\n",
    "        file = l_split[0]\n",
    "        key = l_split[1]\n",
    "\n",
    "        f1 = h5.File(file,'r')\n",
    "        group = f1[key]\n",
    "\n",
    "        labels = np.array(list(group['FeatureLabels'])).astype('U13')\n",
    "        bdan_indis = []\n",
    "        for b in bands:\n",
    "            bdan_indis.append(np.where(labels==b)[0][0])\n",
    "\n",
    "        rad_images[data_index] = np.array(group['ImageFeatures'])[bdan_indis]\n",
    "\n",
    "        mask_images[data_index] = np.array(group['ImageClassification'])\n",
    "\n",
    "        data_index+=1\n",
    "        f1.close()\n",
    "    print(np.shape(rad_images))\n",
    "    rad_images_reshaped = np.swapaxes(np.swapaxes(rad_images,2,1),2,3)\n",
    "    print(np.shape(rad_images_reshaped))\n",
    "    \n",
    "    return rad_images_reshaped, mask_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502788fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Band_1.0', 'Band_2.0', 'Band_20.0', 'Band_26.0', 'Band_27.0', 'Band_29.0', 'Band_31.0', 'Band_32.0', 'Band_35.0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db6dec5ce3d47b7a3a144b75c5a8b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9, 64, 64)\n",
      "(500, 64, 64, 9)\n"
     ]
    }
   ],
   "source": [
    "bands_to_use = [1,2,20,26,27,29,31,32,35]\n",
    "rad_1km, cmasks = get_modis_data(bands_to_use, np.array(use_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f133a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_mm(x):\n",
    "    return ((x-np.min(x))/(np.max(x)-np.min(x)), np.min(x), np.max(x))\n",
    "def norm(x,tr_min,tr_max):\n",
    "    return (x-tr_min)/(tr_max-tr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8fa1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_1km_norm = np.zeros(np.shape(rad_1km))\n",
    "\n",
    "min_max_vals = []\n",
    "for c in range(rad_1km_norm.shape[-1]):\n",
    "    rad_1km_norm[:,:,:,c], c_min, c_max = norm_mm(rad_1km[:,:,:,c])\n",
    "    min_max_vals.append((c_min,c_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae08e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary(mask):\n",
    "    bin_mask = np.copy(mask)\n",
    "    bin_mask[bin_mask==1] = 0\n",
    "    bin_mask[bin_mask==2] = 1\n",
    "    bin_mask[bin_mask==3] = 1\n",
    "    return bin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbdcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmasks_binary = make_binary(cmasks)\n",
    "# human_masks_binary_good = make_binary(human_masks_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f694f",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d3a0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=63099\n",
    "def reset_seeds(reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  # optional\n",
    "\n",
    "    np.random.seed(N)\n",
    "    random.seed(N)\n",
    "    tf.compat.v1.set_random_seed(N)\n",
    "    print(\"RANDOM SEEDS RESET\")  # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4626abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "rng = np.random.default_rng(seed=N)\n",
    "shuffle_indis = np.arange(0,400)\n",
    "rng.shuffle(shuffle_indis)\n",
    "\n",
    "rad_1km_norm_shuffle = np.zeros(np.shape(rad_1km_norm))\n",
    "cmasks_binary_shuffle = np.zeros(np.shape(cmasks_binary))\n",
    "\n",
    "rad_1km_norm_shuffle[0:400] = rad_1km_norm[shuffle_indis]\n",
    "cmasks_binary_shuffle[0:400] = cmasks_binary[shuffle_indis]\n",
    "\n",
    "rad_1km_norm_shuffle[400:]  = rad_1km_norm[400:]\n",
    "cmasks_binary_shuffle[400:]  = cmasks_binary[400:]\n",
    "\n",
    "rad_1km_norm = None\n",
    "cmasks_binary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e898cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 10:53:07.082207: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-06-19 10:53:07.084535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:82:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2024-06-19 10:53:07.084602: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-06-19 10:53:07.084653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-06-19 10:53:07.084688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-06-19 10:53:07.084720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-06-19 10:53:07.084750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-06-19 10:53:07.084779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-06-19 10:53:07.084810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-06-19 10:53:07.084842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-06-19 10:53:07.087524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-06-19 10:53:07.087586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-06-19 10:53:07.087599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-06-19 10:53:07.087607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-06-19 10:53:07.090372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22475 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:82:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "# labels_1hot = tf.one_hot(cmasks_binary,2)\n",
    "# training_masks = labels_1hot\n",
    "training_rad = rad_1km_norm_shuffle[0:350]\n",
    "validate_rad = rad_1km_norm_shuffle[350:400]\n",
    "testing_rad  = rad_1km_norm_shuffle[400: ]\n",
    "training_cmask = cmasks_binary_shuffle[0:350]\n",
    "validate_cmask = cmasks_binary_shuffle[350:400]\n",
    "testing_cmask  = cmasks_binary_shuffle[400: ]\n",
    "\n",
    "IMG_DIM=64\n",
    "LENGTH_OF_DATASET, IMG_DIM_X, IMG_DIM_Y, NUM_OF_CHANNELS = np.shape(training_rad)\n",
    "CLASSES = 2\n",
    "\n",
    "# flattened arrays for MLP Dense and RFs\n",
    "train_rad_flat = training_rad.reshape(-1, training_rad.shape[-1])\n",
    "train_labels_1hot = tf.one_hot(training_cmask.reshape(-1),2)\n",
    "\n",
    "valid_rad_flat = validate_rad.reshape(-1, validate_rad.shape[-1])\n",
    "valid_labels_1hot = tf.one_hot(validate_cmask.reshape(-1),2)\n",
    "\n",
    "test_rad_flat = testing_rad.reshape(-1, testing_rad.shape[-1])\n",
    "test_labels_1hot = tf.one_hot(testing_cmask.reshape(-1),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3eaebd",
   "metadata": {},
   "source": [
    "# RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e6adfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band_1.0</th>\n",
       "      <th>Band_2.0</th>\n",
       "      <th>Band_20.0</th>\n",
       "      <th>Band_26.0</th>\n",
       "      <th>Band_27.0</th>\n",
       "      <th>Band_29.0</th>\n",
       "      <th>Band_31.0</th>\n",
       "      <th>Band_32.0</th>\n",
       "      <th>Band_35.0</th>\n",
       "      <th>CMask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044758</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>0.508592</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.649420</td>\n",
       "      <td>0.846491</td>\n",
       "      <td>0.866587</td>\n",
       "      <td>0.872557</td>\n",
       "      <td>0.905468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048349</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>0.510391</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.648056</td>\n",
       "      <td>0.844970</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>0.871668</td>\n",
       "      <td>0.920609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048947</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>0.515384</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.644110</td>\n",
       "      <td>0.843450</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>0.871668</td>\n",
       "      <td>0.914568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.050774</td>\n",
       "      <td>0.504934</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.644061</td>\n",
       "      <td>0.842963</td>\n",
       "      <td>0.864684</td>\n",
       "      <td>0.869892</td>\n",
       "      <td>0.905390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052864</td>\n",
       "      <td>0.059522</td>\n",
       "      <td>0.498084</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>0.642551</td>\n",
       "      <td>0.837854</td>\n",
       "      <td>0.859976</td>\n",
       "      <td>0.866239</td>\n",
       "      <td>0.912999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409595</th>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.023269</td>\n",
       "      <td>0.418263</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.578291</td>\n",
       "      <td>0.831103</td>\n",
       "      <td>0.862280</td>\n",
       "      <td>0.879171</td>\n",
       "      <td>0.913234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409596</th>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.023582</td>\n",
       "      <td>0.419598</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.572786</td>\n",
       "      <td>0.831164</td>\n",
       "      <td>0.862280</td>\n",
       "      <td>0.878282</td>\n",
       "      <td>0.917863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409597</th>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.419134</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>0.575514</td>\n",
       "      <td>0.830191</td>\n",
       "      <td>0.861378</td>\n",
       "      <td>0.880158</td>\n",
       "      <td>0.903428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409598</th>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.419134</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>0.571373</td>\n",
       "      <td>0.830191</td>\n",
       "      <td>0.861378</td>\n",
       "      <td>0.878381</td>\n",
       "      <td>0.911352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409599</th>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>0.421862</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>0.571373</td>\n",
       "      <td>0.830252</td>\n",
       "      <td>0.860377</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>0.901859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409600 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Band_1.0  Band_2.0  Band_20.0  Band_26.0  Band_27.0  Band_29.0  \\\n",
       "0       0.044758  0.049615   0.508592   0.010795   0.649420   0.846491   \n",
       "1       0.048349  0.053914   0.510391   0.010681   0.648056   0.844970   \n",
       "2       0.048947  0.054849   0.515384   0.010279   0.644110   0.843450   \n",
       "3       0.045683  0.050774   0.504934   0.010337   0.644061   0.842963   \n",
       "4       0.052864  0.059522   0.498084   0.010566   0.642551   0.837854   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "409595  0.022293  0.023269   0.418263   0.010789   0.578291   0.831103   \n",
       "409596  0.022569  0.023582   0.419598   0.011234   0.572786   0.831164   \n",
       "409597  0.022183  0.022956   0.419134   0.011290   0.575514   0.830191   \n",
       "409598  0.022790  0.023778   0.419134   0.010343   0.571373   0.830191   \n",
       "409599  0.024006  0.025421   0.421862   0.010343   0.571373   0.830252   \n",
       "\n",
       "        Band_31.0  Band_32.0  Band_35.0  CMask  \n",
       "0        0.866587   0.872557   0.905468      1  \n",
       "1        0.865685   0.871668   0.920609      1  \n",
       "2        0.865685   0.871668   0.914568      1  \n",
       "3        0.864684   0.869892   0.905390      1  \n",
       "4        0.859976   0.866239   0.912999      1  \n",
       "...           ...        ...        ...    ...  \n",
       "409595   0.862280   0.879171   0.913234      1  \n",
       "409596   0.862280   0.878282   0.917863      1  \n",
       "409597   0.861378   0.880158   0.903428      1  \n",
       "409598   0.861378   0.878381   0.911352      1  \n",
       "409599   0.860377   0.877493   0.901859      1  \n",
       "\n",
       "[409600 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format data in df for RFs\n",
    "train_df = pd.DataFrame(data=train_rad_flat, columns=format_bands_to_use(bands_to_use))\n",
    "train_df.insert(9,\"CMask\", training_cmask.reshape(-1))\n",
    "train_df['CMask'] = train_df['CMask'].astype(int)\n",
    "test_df = pd.DataFrame(data=test_rad_flat, columns=format_bands_to_use(bands_to_use))\n",
    "test_df.insert(9,\"CMask\", testing_cmask.reshape(-1))\n",
    "test_df['CMask'] = test_df['CMask'].astype(int)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "051f0eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 1433600 examples\n",
      "Model trained in 0:00:09.079462\n",
      "Train model on 1433600 examples\n",
      "Model trained in 0:00:48.489992\n",
      "Train model on 1433600 examples\n",
      "Model trained in 0:00:56.781803\n"
     ]
    }
   ],
   "source": [
    "rf_compact = ydf.RandomForestLearner(label=\"CMask\", \n",
    "                                features=format_bands_to_use(bands_to_use),\n",
    "                                num_trees=100,\n",
    "                                random_seed=N,\n",
    "                                max_depth=4\n",
    "                               ).train(train_df)\n",
    "rf_deep = ydf.RandomForestLearner(label=\"CMask\", \n",
    "                                features=format_bands_to_use(bands_to_use),\n",
    "                                num_trees=250,\n",
    "                                random_seed=N,\n",
    "                                max_depth=16\n",
    "                               ).train(train_df)\n",
    "rf_wide = ydf.RandomForestLearner(label=\"CMask\", \n",
    "                                features=format_bands_to_use(bands_to_use),\n",
    "                                num_trees=500,\n",
    "                                random_seed=N,\n",
    "                                max_depth=8\n",
    "                               ).train(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b707b516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".tab_block .header {\n",
       "    flex-direction: row;\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab {\n",
       "    cursor: pointer;\n",
       "    background-color: #F6F5F5;\n",
       "    text-decoration: none;\n",
       "    text-align: center;\n",
       "    padding: 4px 12px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab.selected {\n",
       "    border-bottom: 2px solid #2F80ED;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab:hover {\n",
       "    text-decoration: none;\n",
       "    background-color: #DCDCDC;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content {\n",
       "    display: none;\n",
       "    padding: 5px;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content.selected {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".ydf_pre {\n",
       "    font-size: medium;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".variable_importance {\n",
       "}\n",
       "\n",
       ".variable_importance select {\n",
       "}\n",
       "\n",
       ".variable_importance .content {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".variable_importance .content.selected {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table {\n",
       "  border-collapse: collapse;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table th {\n",
       "  background-color: #ededed;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table td {\n",
       "  text-align: right;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table .best {\n",
       "  background-color: khaki;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "\n",
       "function ydfShowTab(block_id, item) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    \n",
       "    \n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab selected\"));\n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab_content selected\"));\n",
       "    \n",
       "    block.getElementsByClassName(\"tab selected\")[0].classList.remove(\"selected\");\n",
       "    block.getElementsByClassName(\"tab_content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_\" + item).classList.add(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "  \n",
       "\n",
       "function ydfShowVariableImportance(block_id) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    const item = block.getElementsByTagName(\"select\")[0].value;\n",
       "    block.getElementsByClassName(\"content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "\n",
       "</script>\n",
       "  <div class=\"tab_block\" id=\"aae1-23ff-f7a6-8285\"><div class=\"header\"><a id=\"aae1-23ff-f7a6-8285_model\" class=\"tab selected\" onclick=\"ydfShowTab('aae1-23ff-f7a6-8285', 'model')\">Model</a><a id=\"aae1-23ff-f7a6-8285_dataspec\" class=\"tab\" onclick=\"ydfShowTab('aae1-23ff-f7a6-8285', 'dataspec')\">Dataspec</a><a id=\"aae1-23ff-f7a6-8285_training\" class=\"tab\" onclick=\"ydfShowTab('aae1-23ff-f7a6-8285', 'training')\">Training</a><a id=\"aae1-23ff-f7a6-8285_variable_importance\" class=\"tab\" onclick=\"ydfShowTab('aae1-23ff-f7a6-8285', 'variable_importance')\">Variable importances</a><a id=\"aae1-23ff-f7a6-8285_structure\" class=\"tab\" onclick=\"ydfShowTab('aae1-23ff-f7a6-8285', 'structure')\">Structure</a></div><div class=\"body\"><div id=\"aae1-23ff-f7a6-8285_body_model\" class=\"tab_content selected\"><b>Name</b> : RANDOM_FOREST<br><b>Task</b> : CLASSIFICATION<br><b>Label</b> : CMask<br><b>Features (9)</b> : Band_1.0 Band_2.0 Band_20.0 Band_26.0 Band_27.0 Band_29.0 Band_31.0 Band_32.0 Band_35.0<br><b>Weights</b> : None<br><b>Trained with tuner</b> : No<br><b>Model size</b> : 370 kB<br></div><div id=\"aae1-23ff-f7a6-8285_body_dataspec\" class=\"tab_content\"><pre class=\"ydf_pre\">Number of records: 1433600\n",
       "Number of columns: 10\n",
       "\n",
       "Number of columns by type:\n",
       "\tNUMERICAL: 9 (90%)\n",
       "\tCATEGORICAL: 1 (10%)\n",
       "\n",
       "Columns:\n",
       "\n",
       "NUMERICAL: 9 (90%)\n",
       "\t0: &quot;Band_1.0&quot; NUMERICAL mean:0.117824 min:0 max:0.919382 sd:0.141601 dtype:DTYPE_FLOAT64\n",
       "\t1: &quot;Band_2.0&quot; NUMERICAL mean:0.140555 min:0 max:1 sd:0.173942 dtype:DTYPE_FLOAT64\n",
       "\t2: &quot;Band_20.0&quot; NUMERICAL mean:0.39962 min:0 max:1 sd:0.151778 dtype:DTYPE_FLOAT64\n",
       "\t3: &quot;Band_26.0&quot; NUMERICAL mean:0.0368884 min:0 max:1 sd:0.0714152 dtype:DTYPE_FLOAT64\n",
       "\t4: &quot;Band_27.0&quot; NUMERICAL mean:0.478236 min:0 max:1 sd:0.134093 dtype:DTYPE_FLOAT64\n",
       "\t5: &quot;Band_29.0&quot; NUMERICAL mean:0.684862 min:0 max:1 sd:0.198256 dtype:DTYPE_FLOAT64\n",
       "\t6: &quot;Band_31.0&quot; NUMERICAL mean:0.71832 min:0 max:1 sd:0.194286 dtype:DTYPE_FLOAT64\n",
       "\t7: &quot;Band_32.0&quot; NUMERICAL mean:0.733801 min:0 max:1 sd:0.193531 dtype:DTYPE_FLOAT64\n",
       "\t8: &quot;Band_35.0&quot; NUMERICAL mean:0.797049 min:0 max:0.990586 sd:0.154536 dtype:DTYPE_FLOAT64\n",
       "\n",
       "CATEGORICAL: 1 (10%)\n",
       "\t9: &quot;CMask&quot; CATEGORICAL has-dict vocab-size:3 zero-ood-items most-frequent:&quot;0&quot; 770465 (53.7434%) dtype:DTYPE_INT64\n",
       "\n",
       "Terminology:\n",
       "\tnas: Number of non-available (i.e. missing) values.\n",
       "\tood: Out of dictionary.\n",
       "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
       "\ttokenized: The attribute value is obtained through tokenization.\n",
       "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
       "\tvocab-size: Number of unique values.\n",
       "</pre></div><div id=\"aae1-23ff-f7a6-8285_body_training\" class=\"tab_content\"><p>The following evaluation is computed on the validation or out-of-bag dataset.</p><pre class=\"ydf_pre\">Number of predictions (without weights): 1433600\n",
       "Number of predictions (with weights): 1.4336e+06\n",
       "Task: CLASSIFICATION\n",
       "Label: CMask\n",
       "\n",
       "Accuracy: 0.890279  CI95[W][0.889849 0.890708]\n",
       "LogLoss: : 0.857862\n",
       "ErrorRate: : 0.109721\n",
       "\n",
       "Default Accuracy: : 0.537434\n",
       "Default LogLoss: : 0.690342\n",
       "Default ErrorRate: : 0.462566\n",
       "\n",
       "Confusion Table:\n",
       "truth\\prediction\n",
       "            0       1\n",
       "    0  680685   89780\n",
       "    1   67516  595619\n",
       "Total: 1.4336e+06\n",
       "\n",
       "</pre><div style='display: grid; gap: 0px; grid-auto-columns: min-content;'><div style='grid-row:1 / span 1; grid-column:1 / span 1;'><script src='https://www.gstatic.com/external_hosted/plotly/plotly.min.js'></script>\n",
       "<div id=\"chart_aae1_23ff_f7a6_8285self_eval_item0\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_aae1_23ff_f7a6_8285self_eval_item0',\n",
       "    [{\n",
       "x: [1,11,21,31,41,51,61,71,81,91,100],\n",
       "y: [0.889523,0.886259,0.889597,0.889094,0.890056,0.88989,0.889854,0.890197,0.889951,0.890246,0.890279],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'num trees',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'accuracy',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div></div></div><div id=\"aae1-23ff-f7a6-8285_body_variable_importance\" class=\"tab_content\"><p><a target=\"_blank\" href=\"https://ydf.readthedocs.io/en/latest/cli_user_manual#variable-importances\">Variable importances</a> measure the importance of an input feature for a model.</p><div id=\"aae1-23ff-f7a6-8285_vi\" class=\"variable_importance\"><select onchange=\"ydfShowVariableImportance('aae1-23ff-f7a6-8285_vi')\"><option value=\"INV_MEAN_MIN_DEPTH\">INV_MEAN_MIN_DEPTH</option><option value=\"NUM_AS_ROOT\">NUM_AS_ROOT</option><option value=\"NUM_NODES\">NUM_NODES</option><option value=\"SUM_SCORE\">SUM_SCORE</option></select><div id=\"aae1-23ff-f7a6-8285_vi_body_INV_MEAN_MIN_DEPTH\" class=\"content selected\"><pre class=\"ydf_pre\">    1.  &quot;Band_2.0&quot;  0.352734 ################\n",
       "    2. &quot;Band_31.0&quot;  0.338983 #############\n",
       "    3. &quot;Band_32.0&quot;  0.338123 #############\n",
       "    4. &quot;Band_29.0&quot;  0.323363 ###########\n",
       "    5.  &quot;Band_1.0&quot;  0.310800 #########\n",
       "    6. &quot;Band_26.0&quot;  0.294985 ######\n",
       "    7. &quot;Band_20.0&quot;  0.254291 \n",
       "    8. &quot;Band_35.0&quot;  0.250313 \n",
       "</pre></div><div id=\"aae1-23ff-f7a6-8285_vi_body_NUM_AS_ROOT\" class=\"content\"><pre class=\"ydf_pre\">    1. &quot;Band_29.0&quot; 28.000000 ################\n",
       "    2. &quot;Band_32.0&quot; 28.000000 ################\n",
       "    3. &quot;Band_31.0&quot; 27.000000 ###############\n",
       "    4. &quot;Band_26.0&quot; 11.000000 ###\n",
       "    5.  &quot;Band_2.0&quot;  6.000000 \n",
       "</pre></div><div id=\"aae1-23ff-f7a6-8285_vi_body_NUM_NODES\" class=\"content\"><pre class=\"ydf_pre\">    1.  &quot;Band_2.0&quot; 203.000000 ################\n",
       "    2.  &quot;Band_1.0&quot; 149.000000 ###########\n",
       "    3. &quot;Band_31.0&quot; 106.000000 ########\n",
       "    4. &quot;Band_32.0&quot; 86.000000 ######\n",
       "    5. &quot;Band_26.0&quot; 77.000000 #####\n",
       "    6. &quot;Band_29.0&quot; 53.000000 ####\n",
       "    7. &quot;Band_20.0&quot; 24.000000 #\n",
       "    8. &quot;Band_35.0&quot;  2.000000 \n",
       "</pre></div><div id=\"aae1-23ff-f7a6-8285_vi_body_SUM_SCORE\" class=\"content\"><pre class=\"ydf_pre\">    1. &quot;Band_32.0&quot; 11928672.016427 ################\n",
       "    2.  &quot;Band_2.0&quot; 11454031.861301 ###############\n",
       "    3. &quot;Band_31.0&quot; 11419560.710755 ###############\n",
       "    4. &quot;Band_29.0&quot; 9854346.382982 #############\n",
       "    5.  &quot;Band_1.0&quot; 8063787.100260 ##########\n",
       "    6. &quot;Band_26.0&quot; 5352429.059231 #######\n",
       "    7. &quot;Band_20.0&quot; 564190.494482 \n",
       "    8. &quot;Band_35.0&quot; 40696.390302 \n",
       "</pre></div></div><p>Those variable importances are computed during training. More, and possibly more informative, variable importances are available when analyzing a model on a test dataset.</p></div><div id=\"aae1-23ff-f7a6-8285_body_structure\" class=\"tab_content\"><b>Num trees</b> : 100<br><p>Only printing the first tree.</p><pre class=\"ydf_pre\">Tree #0:\n",
       "    &quot;Band_32.0&quot;&gt;=0.802813 [s:0.252584 n:1433600 np:780334 miss:0] ; val:&quot;0&quot; prob:[0.537173, 0.462827]\n",
       "        (pos) &quot;Band_1.0&quot;&gt;=0.0317828 [s:0.0790888 n:780334 np:411911 miss:1] ; val:&quot;1&quot; prob:[0.230142, 0.769858]\n",
       "        |        (pos) &quot;Band_31.0&quot;&gt;=0.853115 [s:0.0856091 n:411911 np:256997 miss:0] ; val:&quot;1&quot; prob:[0.38058, 0.61942]\n",
       "        |        |        (pos) val:&quot;1&quot; prob:[0.225057, 0.774943]\n",
       "        |        |        (neg) val:&quot;0&quot; prob:[0.638587, 0.361413]\n",
       "        |        (neg) &quot;Band_2.0&quot;&gt;=0.0175863 [s:0.0355679 n:368423 np:149384 miss:1] ; val:&quot;1&quot; prob:[0.0619478, 0.938052]\n",
       "        |                 (pos) val:&quot;1&quot; prob:[0.137558, 0.862442]\n",
       "        |                 (neg) val:&quot;1&quot; prob:[0.0103817, 0.989618]\n",
       "        (neg) &quot;Band_2.0&quot;&gt;=0.0200471 [s:0.171009 n:653266 np:601278 miss:1] ; val:&quot;0&quot; prob:[0.903924, 0.0960757]\n",
       "                 (pos) &quot;Band_1.0&quot;&gt;=0.0665626 [s:0.0397437 n:601278 np:494011 miss:1] ; val:&quot;0&quot; prob:[0.972164, 0.0278357]\n",
       "                 |        (pos) val:&quot;0&quot; prob:[0.997688, 0.00231169]\n",
       "                 |        (neg) val:&quot;0&quot; prob:[0.854615, 0.145385]\n",
       "                 (neg) &quot;Band_31.0&quot;&gt;=0.602514 [s:0.0855111 n:51988 np:23333 miss:1] ; val:&quot;1&quot; prob:[0.11468, 0.88532]\n",
       "                          (pos) val:&quot;1&quot; prob:[0.248704, 0.751296]\n",
       "                          (neg) val:&quot;1&quot; prob:[0.00554877, 0.994451]\n",
       "</pre></div></div></div>"
      ],
      "text/plain": [
       "<ydf.utils.html.HtmlNotebookDisplay at 0x2b2a6fedd0a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [rf_compact,rf_deep, rf_wide]\n",
    "models[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dedf3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application time: 0.6832542419433594 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9599994 , 0.9599994 , 0.9599994 , ..., 0.99999934, 0.99999934,\n",
       "       0.99999934], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "eval_rf_compact = rf_compact.predict(test_df)\n",
    "end = time.time()\n",
    "print(f'Application time: {end-start} seconds')\n",
    "CM = eval_rf_compact\n",
    "CM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3853a1",
   "metadata": {},
   "source": [
    "# Batch size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a4cc1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.zeros((4,250))\n",
    "val_accs = np.zeros((4,250))\n",
    "\n",
    "for i in range(1,5):  \n",
    "    out = f'/data/keeling/a/jdnied2/c/MS_THESIS/Models/MLP_batch_size/{10**(i+2)}/'\n",
    "    s = f'{out}/history/hist'\n",
    "\n",
    "    with open(s, \"rb\") as file_pi:\n",
    "        history = pickle.load(file_pi)\n",
    "    accs[i-1] = history['accuracy']\n",
    "    val_accs[i-1] = history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0620dce7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(accs[\u001b[38;5;241m0\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1E3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(accs[\u001b[38;5;241m1\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1E4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "font = {\n",
    "        'size'   : 14\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "plt.plot(accs[0], color='red', label='1E3')\n",
    "plt.plot(accs[1], color='blue', label='1E4')\n",
    "plt.plot(accs[2], color='blueviolet', label='1E5')\n",
    "plt.plot(accs[3], color='black', label='1E6')\n",
    "\n",
    "plt.plot(val_accs[0], '--', color='red')\n",
    "plt.plot(val_accs[1], '--', color='blue')\n",
    "plt.plot(val_accs[2], '--', color='blueviolet')\n",
    "plt.plot(val_accs[3], '--', color='black')\n",
    "plt.ylim((.5,1.))\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('MLPs Adjusting Batch Size')\n",
    "plt.savefig('/data/keeling/a/jdnied2/c/MS_THESIS/Models/Plots/MLPS_batch_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87077a4",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "250e97cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KERAS AND TENSORFLOW GRAPHS RESET\n",
      "RANDOM SEEDS RESET\n",
      "\n",
      " /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-{epoch:04d} \n",
      "\n",
      "Epoch 1/250\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 9), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (20480, 9).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 9), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (20480, 9).\n",
      "57/70 [=======================>......] - ETA: 0s - loss: 0.6582 - accuracy: 0.7016WARNING:tensorflow:Model was constructed with shape (None, 1, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 9), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (20480, 9).\n",
      "70/70 [==============================] - 1s 6ms/step - loss: 0.6503 - accuracy: 0.7109 - val_loss: 0.5320 - val_accuracy: 0.8105\n",
      "\n",
      "Epoch 00001: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0001\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0001/assets\n",
      "Epoch 2/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8082 - val_loss: 0.4158 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00002: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0002\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0002/assets\n",
      "Epoch 3/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8132 - val_loss: 0.3683 - val_accuracy: 0.8176\n",
      "\n",
      "Epoch 00003: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0003\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0003/assets\n",
      "Epoch 4/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8211 - val_loss: 0.3489 - val_accuracy: 0.8238\n",
      "\n",
      "Epoch 00004: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0004\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0004/assets\n",
      "Epoch 5/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8272 - val_loss: 0.3407 - val_accuracy: 0.8299\n",
      "\n",
      "Epoch 00005: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0005\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0005/assets\n",
      "Epoch 6/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8323 - val_loss: 0.3361 - val_accuracy: 0.8338\n",
      "\n",
      "Epoch 00006: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0006\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0006/assets\n",
      "Epoch 7/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8359 - val_loss: 0.3325 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00007: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0007\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0007/assets\n",
      "Epoch 8/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8377 - val_loss: 0.3292 - val_accuracy: 0.8385\n",
      "\n",
      "Epoch 00008: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0008\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0008/assets\n",
      "Epoch 9/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8398 - val_loss: 0.3258 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00009: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0009\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0009/assets\n",
      "Epoch 10/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8411 - val_loss: 0.3224 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00010: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0010\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0010/assets\n",
      "Epoch 11/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8424 - val_loss: 0.3192 - val_accuracy: 0.8439\n",
      "\n",
      "Epoch 00011: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0011\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0011/assets\n",
      "Epoch 12/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8434 - val_loss: 0.3151 - val_accuracy: 0.8452\n",
      "\n",
      "Epoch 00012: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0012\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0012/assets\n",
      "Epoch 13/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8456 - val_loss: 0.3114 - val_accuracy: 0.8458\n",
      "\n",
      "Epoch 00013: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0013\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0013/assets\n",
      "Epoch 14/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8466 - val_loss: 0.3075 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00014: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0014\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0014/assets\n",
      "Epoch 15/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8488 - val_loss: 0.3034 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00015: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0015\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0015/assets\n",
      "Epoch 16/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8500 - val_loss: 0.2994 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00016: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0016\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0016/assets\n",
      "Epoch 17/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2952 - accuracy: 0.8515 - val_loss: 0.2949 - val_accuracy: 0.8532\n",
      "\n",
      "Epoch 00017: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0017\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0017/assets\n",
      "Epoch 18/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8535 - val_loss: 0.2909 - val_accuracy: 0.8552\n",
      "\n",
      "Epoch 00018: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0018\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0018/assets\n",
      "Epoch 19/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8548 - val_loss: 0.2870 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00019: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0019\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0019/assets\n",
      "Epoch 20/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8572 - val_loss: 0.2826 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00020: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0020/assets\n",
      "Epoch 21/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8589 - val_loss: 0.2785 - val_accuracy: 0.8597\n",
      "\n",
      "Epoch 00021: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0021\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0021/assets\n",
      "Epoch 22/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8606 - val_loss: 0.2743 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00022: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0022\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0022/assets\n",
      "Epoch 23/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8634 - val_loss: 0.2702 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00023: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0023\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0023/assets\n",
      "Epoch 24/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8648 - val_loss: 0.2666 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00024: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0024\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0024/assets\n",
      "Epoch 25/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8674 - val_loss: 0.2627 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00025: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0025\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0025/assets\n",
      "Epoch 26/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.8701 - val_loss: 0.2588 - val_accuracy: 0.8676\n",
      "\n",
      "Epoch 00026: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0026\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0026/assets\n",
      "Epoch 27/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8739 - val_loss: 0.2557 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00027: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0027\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0027/assets\n",
      "Epoch 28/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8783 - val_loss: 0.2526 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00028: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0028\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0028/assets\n",
      "Epoch 29/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.8845 - val_loss: 0.2495 - val_accuracy: 0.8759\n",
      "\n",
      "Epoch 00029: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0029\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0029/assets\n",
      "Epoch 30/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.8878 - val_loss: 0.2468 - val_accuracy: 0.8816\n",
      "\n",
      "Epoch 00030: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0030\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0030/assets\n",
      "Epoch 31/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.8929 - val_loss: 0.2436 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00031: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0031\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0031/assets\n",
      "Epoch 32/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.8984 - val_loss: 0.2400 - val_accuracy: 0.9019\n",
      "\n",
      "Epoch 00032: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0032\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0032/assets\n",
      "Epoch 33/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2438 - accuracy: 0.8999 - val_loss: 0.2381 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00033: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0033\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0033/assets\n",
      "Epoch 34/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9029 - val_loss: 0.2348 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00034: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0034\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0034/assets\n",
      "Epoch 35/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9048 - val_loss: 0.2322 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00035: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0035\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0035/assets\n",
      "Epoch 36/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9069 - val_loss: 0.2298 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00036: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0036\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0036/assets\n",
      "Epoch 37/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2318 - accuracy: 0.9089 - val_loss: 0.2275 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00037: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0037\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0037/assets\n",
      "Epoch 38/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9096 - val_loss: 0.2257 - val_accuracy: 0.9116\n",
      "\n",
      "Epoch 00038: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0038\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0038/assets\n",
      "Epoch 39/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2288 - accuracy: 0.9109 - val_loss: 0.2239 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00039: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0039\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0039/assets\n",
      "Epoch 40/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9121 - val_loss: 0.2208 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00040: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0040\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0040/assets\n",
      "Epoch 41/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9128 - val_loss: 0.2184 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00041: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0041\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0041/assets\n",
      "Epoch 42/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2225 - accuracy: 0.9135 - val_loss: 0.2158 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00042: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0042\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0042/assets\n",
      "Epoch 43/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9143 - val_loss: 0.2159 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00043: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0043/assets\n",
      "Epoch 44/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9150 - val_loss: 0.2131 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00044: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0044\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0044/assets\n",
      "Epoch 45/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2169 - accuracy: 0.9160 - val_loss: 0.2132 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00045: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0045\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0045/assets\n",
      "Epoch 46/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2152 - accuracy: 0.9166 - val_loss: 0.2102 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00046: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0046\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0046/assets\n",
      "Epoch 47/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9171 - val_loss: 0.2106 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00047: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0047\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0047/assets\n",
      "Epoch 48/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9180 - val_loss: 0.2067 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00048: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0048\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0048/assets\n",
      "Epoch 49/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9180 - val_loss: 0.2044 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00049: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0049\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0049/assets\n",
      "Epoch 50/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9182 - val_loss: 0.2040 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00050: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0050\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0050/assets\n",
      "Epoch 51/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9186 - val_loss: 0.2055 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00051: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0051\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0051/assets\n",
      "Epoch 52/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9192 - val_loss: 0.2024 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00052: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0052\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0052/assets\n",
      "Epoch 53/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9201 - val_loss: 0.2012 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00053: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0053\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0053/assets\n",
      "Epoch 54/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9199 - val_loss: 0.2000 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00054: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0054\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0054/assets\n",
      "Epoch 55/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9206 - val_loss: 0.2019 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00055: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0055\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0055/assets\n",
      "Epoch 56/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9208 - val_loss: 0.1983 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00056: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0056\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0056/assets\n",
      "Epoch 57/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9211 - val_loss: 0.1963 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00057: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0057\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0057/assets\n",
      "Epoch 58/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9213 - val_loss: 0.1963 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00058: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0058\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0058/assets\n",
      "Epoch 59/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9217 - val_loss: 0.1947 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00059: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0059\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0059/assets\n",
      "Epoch 60/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9220 - val_loss: 0.1955 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00060: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0060\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0060/assets\n",
      "Epoch 61/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9221 - val_loss: 0.1952 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00061: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0061\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0061/assets\n",
      "Epoch 62/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9223 - val_loss: 0.1937 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00062: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0062\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0062/assets\n",
      "Epoch 63/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1973 - accuracy: 0.9226 - val_loss: 0.1922 - val_accuracy: 0.9256\n",
      "\n",
      "Epoch 00063: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0063\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0063/assets\n",
      "Epoch 64/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1964 - accuracy: 0.9227 - val_loss: 0.1914 - val_accuracy: 0.9255\n",
      "\n",
      "Epoch 00064: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0064\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0064/assets\n",
      "Epoch 65/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9230 - val_loss: 0.1935 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00065: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0065\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0065/assets\n",
      "Epoch 66/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9237 - val_loss: 0.1923 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00066: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0066/assets\n",
      "Epoch 67/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9237 - val_loss: 0.1901 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00067: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0067\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0067/assets\n",
      "Epoch 68/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9238 - val_loss: 0.1940 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00068: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0068\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0068/assets\n",
      "Epoch 69/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9239 - val_loss: 0.1923 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00069: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0069\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0069/assets\n",
      "Epoch 70/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9238 - val_loss: 0.1883 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00070: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0070\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0070/assets\n",
      "Epoch 71/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9240 - val_loss: 0.1882 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00071: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0071\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0071/assets\n",
      "Epoch 72/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.9246 - val_loss: 0.1909 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00072: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0072\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0072/assets\n",
      "Epoch 73/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9242 - val_loss: 0.1907 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00073: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0073\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0073/assets\n",
      "Epoch 74/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1909 - accuracy: 0.9248 - val_loss: 0.1879 - val_accuracy: 0.9298\n",
      "\n",
      "Epoch 00074: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0074\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0074/assets\n",
      "Epoch 75/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9241 - val_loss: 0.1885 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00075: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0075\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0075/assets\n",
      "Epoch 76/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9251 - val_loss: 0.1874 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00076: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0076\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0076/assets\n",
      "Epoch 77/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9247 - val_loss: 0.1863 - val_accuracy: 0.9304\n",
      "\n",
      "Epoch 00077: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0077\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0077/assets\n",
      "Epoch 78/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9250 - val_loss: 0.1868 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00078: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0078\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0078/assets\n",
      "Epoch 79/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9255 - val_loss: 0.1846 - val_accuracy: 0.9301\n",
      "\n",
      "Epoch 00079: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0079\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0079/assets\n",
      "Epoch 80/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9257 - val_loss: 0.1852 - val_accuracy: 0.9312\n",
      "\n",
      "Epoch 00080: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0080\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0080/assets\n",
      "Epoch 81/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9256 - val_loss: 0.1860 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00081: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0081\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0081/assets\n",
      "Epoch 82/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9258 - val_loss: 0.1830 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00082: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0082\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0082/assets\n",
      "Epoch 83/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9253 - val_loss: 0.1821 - val_accuracy: 0.9297\n",
      "\n",
      "Epoch 00083: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0083\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0083/assets\n",
      "Epoch 84/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9257 - val_loss: 0.1858 - val_accuracy: 0.9331\n",
      "\n",
      "Epoch 00084: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0084\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0084/assets\n",
      "Epoch 85/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1868 - accuracy: 0.9257 - val_loss: 0.1818 - val_accuracy: 0.9306\n",
      "\n",
      "Epoch 00085: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0085\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0085/assets\n",
      "Epoch 86/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9260 - val_loss: 0.1819 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00086: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0086\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0086/assets\n",
      "Epoch 87/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9264 - val_loss: 0.1818 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00087: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0087\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0087/assets\n",
      "Epoch 88/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9261 - val_loss: 0.1810 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00088: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0088\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0088/assets\n",
      "Epoch 89/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1860 - accuracy: 0.9258 - val_loss: 0.1856 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00089: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0089/assets\n",
      "Epoch 90/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9263 - val_loss: 0.1804 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00090: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0090\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0090/assets\n",
      "Epoch 91/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9263 - val_loss: 0.1822 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00091: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0091\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0091/assets\n",
      "Epoch 92/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9263 - val_loss: 0.1795 - val_accuracy: 0.9328\n",
      "\n",
      "Epoch 00092: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0092\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0092/assets\n",
      "Epoch 93/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9261 - val_loss: 0.1795 - val_accuracy: 0.9332\n",
      "\n",
      "Epoch 00093: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0093\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0093/assets\n",
      "Epoch 94/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9265 - val_loss: 0.1783 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00094: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0094\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0094/assets\n",
      "Epoch 95/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9268 - val_loss: 0.1804 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00095: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0095\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0095/assets\n",
      "Epoch 96/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9266 - val_loss: 0.1800 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00096: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0096\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0096/assets\n",
      "Epoch 97/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9268 - val_loss: 0.1774 - val_accuracy: 0.9332\n",
      "\n",
      "Epoch 00097: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0097\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0097/assets\n",
      "Epoch 98/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9266 - val_loss: 0.1763 - val_accuracy: 0.9329\n",
      "\n",
      "Epoch 00098: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0098\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0098/assets\n",
      "Epoch 99/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9271 - val_loss: 0.1779 - val_accuracy: 0.9346\n",
      "\n",
      "Epoch 00099: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0099\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0099/assets\n",
      "Epoch 100/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9270 - val_loss: 0.1785 - val_accuracy: 0.9355\n",
      "\n",
      "Epoch 00100: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0100\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0100/assets\n",
      "Epoch 101/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9269 - val_loss: 0.1756 - val_accuracy: 0.9342\n",
      "\n",
      "Epoch 00101: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0101\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0101/assets\n",
      "Epoch 102/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9274 - val_loss: 0.1756 - val_accuracy: 0.9346\n",
      "\n",
      "Epoch 00102: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0102\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0102/assets\n",
      "Epoch 103/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.9269 - val_loss: 0.1756 - val_accuracy: 0.9348\n",
      "\n",
      "Epoch 00103: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0103\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0103/assets\n",
      "Epoch 104/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9277 - val_loss: 0.1752 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00104: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0104\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0104/assets\n",
      "Epoch 105/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9275 - val_loss: 0.1731 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00105: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0105\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0105/assets\n",
      "Epoch 106/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1808 - accuracy: 0.9275 - val_loss: 0.1764 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00106: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0106\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0106/assets\n",
      "Epoch 107/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1816 - accuracy: 0.9274 - val_loss: 0.1770 - val_accuracy: 0.9368\n",
      "\n",
      "Epoch 00107: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0107\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0107/assets\n",
      "Epoch 108/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9275 - val_loss: 0.1745 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00108: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0108\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0108/assets\n",
      "Epoch 109/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 0.9273 - val_loss: 0.1717 - val_accuracy: 0.9342\n",
      "\n",
      "Epoch 00109: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0109\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0109/assets\n",
      "Epoch 110/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9277 - val_loss: 0.1718 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00110: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0110\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0110/assets\n",
      "Epoch 111/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9278 - val_loss: 0.1731 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00111: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0111\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0111/assets\n",
      "Epoch 112/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9277 - val_loss: 0.1734 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00112: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0112/assets\n",
      "Epoch 113/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9279 - val_loss: 0.1715 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00113: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0113\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0113/assets\n",
      "Epoch 114/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9280 - val_loss: 0.1727 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00114: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0114\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0114/assets\n",
      "Epoch 115/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9280 - val_loss: 0.1719 - val_accuracy: 0.9372\n",
      "\n",
      "Epoch 00115: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0115\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0115/assets\n",
      "Epoch 116/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9283 - val_loss: 0.1733 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00116: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0116\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0116/assets\n",
      "Epoch 117/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9279 - val_loss: 0.1706 - val_accuracy: 0.9370\n",
      "\n",
      "Epoch 00117: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0117\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0117/assets\n",
      "Epoch 118/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9281 - val_loss: 0.1712 - val_accuracy: 0.9377\n",
      "\n",
      "Epoch 00118: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0118\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0118/assets\n",
      "Epoch 119/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9283 - val_loss: 0.1715 - val_accuracy: 0.9383\n",
      "\n",
      "Epoch 00119: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0119\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0119/assets\n",
      "Epoch 120/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9284 - val_loss: 0.1708 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00120: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0120\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0120/assets\n",
      "Epoch 121/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1779 - accuracy: 0.9282 - val_loss: 0.1681 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00121: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0121\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0121/assets\n",
      "Epoch 122/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9278 - val_loss: 0.1676 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00122: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0122\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0122/assets\n",
      "Epoch 123/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9281 - val_loss: 0.1676 - val_accuracy: 0.9374\n",
      "\n",
      "Epoch 00123: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0123\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0123/assets\n",
      "Epoch 124/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9281 - val_loss: 0.1683 - val_accuracy: 0.9382\n",
      "\n",
      "Epoch 00124: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0124\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0124/assets\n",
      "Epoch 125/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9288 - val_loss: 0.1655 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00125: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0125\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0125/assets\n",
      "Epoch 126/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9288 - val_loss: 0.1658 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00126: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0126\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0126/assets\n",
      "Epoch 127/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9290 - val_loss: 0.1658 - val_accuracy: 0.9377\n",
      "\n",
      "Epoch 00127: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0127\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0127/assets\n",
      "Epoch 128/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9284 - val_loss: 0.1660 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00128: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0128\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0128/assets\n",
      "Epoch 129/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9286 - val_loss: 0.1660 - val_accuracy: 0.9390\n",
      "\n",
      "Epoch 00129: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0129\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0129/assets\n",
      "Epoch 130/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9289 - val_loss: 0.1635 - val_accuracy: 0.9365\n",
      "\n",
      "Epoch 00130: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0130\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0130/assets\n",
      "Epoch 131/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9291 - val_loss: 0.1642 - val_accuracy: 0.9380\n",
      "\n",
      "Epoch 00131: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0131\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0131/assets\n",
      "Epoch 132/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9291 - val_loss: 0.1642 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00132: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0132\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0132/assets\n",
      "Epoch 133/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9289 - val_loss: 0.1630 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00133: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0133\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0133/assets\n",
      "Epoch 134/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9289 - val_loss: 0.1643 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00134: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0134\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0134/assets\n",
      "Epoch 135/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1742 - accuracy: 0.9290 - val_loss: 0.1617 - val_accuracy: 0.9379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00135: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0135\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0135/assets\n",
      "Epoch 136/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9293 - val_loss: 0.1617 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00136: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0136\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0136/assets\n",
      "Epoch 137/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9293 - val_loss: 0.1625 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00137: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0137\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0137/assets\n",
      "Epoch 138/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9293 - val_loss: 0.1618 - val_accuracy: 0.9398\n",
      "\n",
      "Epoch 00138: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0138\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0138/assets\n",
      "Epoch 139/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9292 - val_loss: 0.1625 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00139: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0139\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0139/assets\n",
      "Epoch 140/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9294 - val_loss: 0.1610 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00140: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0140\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0140/assets\n",
      "Epoch 141/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9294 - val_loss: 0.1598 - val_accuracy: 0.9394\n",
      "\n",
      "Epoch 00141: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0141\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0141/assets\n",
      "Epoch 142/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9294 - val_loss: 0.1605 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00142: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0142\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0142/assets\n",
      "Epoch 143/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9299 - val_loss: 0.1596 - val_accuracy: 0.9401\n",
      "\n",
      "Epoch 00143: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0143\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0143/assets\n",
      "Epoch 144/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9299 - val_loss: 0.1597 - val_accuracy: 0.9406\n",
      "\n",
      "Epoch 00144: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0144\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0144/assets\n",
      "Epoch 145/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9300 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00145: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0145\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0145/assets\n",
      "Epoch 146/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9299 - val_loss: 0.1583 - val_accuracy: 0.9402\n",
      "\n",
      "Epoch 00146: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0146\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0146/assets\n",
      "Epoch 147/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9299 - val_loss: 0.1597 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00147: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0147\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0147/assets\n",
      "Epoch 148/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9303 - val_loss: 0.1580 - val_accuracy: 0.9409\n",
      "\n",
      "Epoch 00148: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0148\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0148/assets\n",
      "Epoch 149/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9303 - val_loss: 0.1588 - val_accuracy: 0.9416\n",
      "\n",
      "Epoch 00149: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0149\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0149/assets\n",
      "Epoch 150/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1704 - accuracy: 0.9304 - val_loss: 0.1571 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00150: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0150\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0150/assets\n",
      "Epoch 151/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9302 - val_loss: 0.1574 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00151: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0151\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0151/assets\n",
      "Epoch 152/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9306 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "\n",
      "Epoch 00152: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0152\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0152/assets\n",
      "Epoch 153/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9306 - val_loss: 0.1553 - val_accuracy: 0.9402\n",
      "\n",
      "Epoch 00153: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0153\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0153/assets\n",
      "Epoch 154/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9307 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00154: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0154\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0154/assets\n",
      "Epoch 155/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9304 - val_loss: 0.1553 - val_accuracy: 0.9412\n",
      "\n",
      "Epoch 00155: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0155\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0155/assets\n",
      "Epoch 156/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9309 - val_loss: 0.1567 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00156: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0156\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0156/assets\n",
      "Epoch 157/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9310 - val_loss: 0.1557 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00157: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0157\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0157/assets\n",
      "Epoch 158/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9315 - val_loss: 0.1557 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00158: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0158\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0158/assets\n",
      "Epoch 159/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9316 - val_loss: 0.1551 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00159: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0159\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0159/assets\n",
      "Epoch 160/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9315 - val_loss: 0.1538 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00160: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0160\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0160/assets\n",
      "Epoch 161/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9312 - val_loss: 0.1531 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00161: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0161\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0161/assets\n",
      "Epoch 162/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1671 - accuracy: 0.9317 - val_loss: 0.1535 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00162: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0162\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0162/assets\n",
      "Epoch 163/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1683 - accuracy: 0.9314 - val_loss: 0.1536 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00163: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0163\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0163/assets\n",
      "Epoch 164/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9316 - val_loss: 0.1532 - val_accuracy: 0.9427\n",
      "\n",
      "Epoch 00164: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0164\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0164/assets\n",
      "Epoch 165/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9313 - val_loss: 0.1526 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00165: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0165\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0165/assets\n",
      "Epoch 166/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9320 - val_loss: 0.1518 - val_accuracy: 0.9418\n",
      "\n",
      "Epoch 00166: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0166\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0166/assets\n",
      "Epoch 167/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9320 - val_loss: 0.1521 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00167: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0167\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0167/assets\n",
      "Epoch 168/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9322 - val_loss: 0.1519 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00168: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0168\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0168/assets\n",
      "Epoch 169/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9326 - val_loss: 0.1510 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00169: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0169\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0169/assets\n",
      "Epoch 170/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9323 - val_loss: 0.1521 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00170: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0170\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0170/assets\n",
      "Epoch 171/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9324 - val_loss: 0.1501 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00171: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0171\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0171/assets\n",
      "Epoch 172/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9323 - val_loss: 0.1508 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00172: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0172\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0172/assets\n",
      "Epoch 173/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9324 - val_loss: 0.1498 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00173: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0173\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0173/assets\n",
      "Epoch 174/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9324 - val_loss: 0.1502 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00174: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0174\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0174/assets\n",
      "Epoch 175/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9327 - val_loss: 0.1490 - val_accuracy: 0.9419\n",
      "\n",
      "Epoch 00175: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0175\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0175/assets\n",
      "Epoch 176/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9333 - val_loss: 0.1491 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00176: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0176\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0176/assets\n",
      "Epoch 177/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9329 - val_loss: 0.1498 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00177: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0177\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0177/assets\n",
      "Epoch 178/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1649 - accuracy: 0.9328 - val_loss: 0.1513 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00178: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0178\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0178/assets\n",
      "Epoch 179/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9329 - val_loss: 0.1485 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00179: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0179\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0179/assets\n",
      "Epoch 180/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9335 - val_loss: 0.1484 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00180: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0180\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0180/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9328 - val_loss: 0.1501 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00181: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0181\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0181/assets\n",
      "Epoch 182/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9332 - val_loss: 0.1485 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00182: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0182\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0182/assets\n",
      "Epoch 183/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9332 - val_loss: 0.1476 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00183: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0183\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0183/assets\n",
      "Epoch 184/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9331 - val_loss: 0.1478 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00184: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0184\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0184/assets\n",
      "Epoch 185/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9335 - val_loss: 0.1469 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00185: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0185\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0185/assets\n",
      "Epoch 186/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9337 - val_loss: 0.1472 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00186: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0186\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0186/assets\n",
      "Epoch 187/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9339 - val_loss: 0.1473 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00187: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0187\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0187/assets\n",
      "Epoch 188/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9336 - val_loss: 0.1464 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00188: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0188\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0188/assets\n",
      "Epoch 189/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9339 - val_loss: 0.1462 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00189: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0189\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0189/assets\n",
      "Epoch 190/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9341 - val_loss: 0.1461 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00190: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0190\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0190/assets\n",
      "Epoch 191/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9339 - val_loss: 0.1462 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00191: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0191\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0191/assets\n",
      "Epoch 192/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9342 - val_loss: 0.1455 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00192: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0192\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0192/assets\n",
      "Epoch 193/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1623 - accuracy: 0.9339 - val_loss: 0.1469 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00193: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0193\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0193/assets\n",
      "Epoch 194/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9341 - val_loss: 0.1453 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00194: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0194\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0194/assets\n",
      "Epoch 195/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9342 - val_loss: 0.1454 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00195: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0195\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0195/assets\n",
      "Epoch 196/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9346 - val_loss: 0.1450 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00196: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0196\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0196/assets\n",
      "Epoch 197/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9345 - val_loss: 0.1451 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00197: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0197\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0197/assets\n",
      "Epoch 198/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9345 - val_loss: 0.1451 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00198: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0198\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0198/assets\n",
      "Epoch 199/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9344 - val_loss: 0.1447 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00199: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0199\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0199/assets\n",
      "Epoch 200/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9343 - val_loss: 0.1444 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00200: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0200\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0200/assets\n",
      "Epoch 201/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9346 - val_loss: 0.1445 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00201: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0201\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0201/assets\n",
      "Epoch 202/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9347 - val_loss: 0.1446 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00202: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0202\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0202/assets\n",
      "Epoch 203/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9349 - val_loss: 0.1443 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00203: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0203\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0203/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9350 - val_loss: 0.1437 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00204: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0204\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0204/assets\n",
      "Epoch 205/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9348 - val_loss: 0.1434 - val_accuracy: 0.9440\n",
      "\n",
      "Epoch 00205: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0205\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0205/assets\n",
      "Epoch 206/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9347 - val_loss: 0.1441 - val_accuracy: 0.9456\n",
      "\n",
      "Epoch 00206: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0206\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0206/assets\n",
      "Epoch 207/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9345 - val_loss: 0.1433 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00207: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0207\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0207/assets\n",
      "Epoch 208/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9351 - val_loss: 0.1445 - val_accuracy: 0.9464\n",
      "\n",
      "Epoch 00208: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0208\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0208/assets\n",
      "Epoch 209/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9345 - val_loss: 0.1431 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00209: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0209\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0209/assets\n",
      "Epoch 210/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1591 - accuracy: 0.9351 - val_loss: 0.1439 - val_accuracy: 0.9461\n",
      "\n",
      "Epoch 00210: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0210\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0210/assets\n",
      "Epoch 211/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9351 - val_loss: 0.1429 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00211: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0211\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0211/assets\n",
      "Epoch 212/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9352 - val_loss: 0.1427 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00212: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0212\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0212/assets\n",
      "Epoch 213/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9353 - val_loss: 0.1427 - val_accuracy: 0.9453\n",
      "\n",
      "Epoch 00213: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0213\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0213/assets\n",
      "Epoch 214/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9352 - val_loss: 0.1429 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00214: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0214\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0214/assets\n",
      "Epoch 215/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9351 - val_loss: 0.1423 - val_accuracy: 0.9455\n",
      "\n",
      "Epoch 00215: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0215\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0215/assets\n",
      "Epoch 216/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9352 - val_loss: 0.1425 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00216: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0216\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0216/assets\n",
      "Epoch 217/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9354 - val_loss: 0.1424 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00217: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0217\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0217/assets\n",
      "Epoch 218/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9352 - val_loss: 0.1423 - val_accuracy: 0.9463\n",
      "\n",
      "Epoch 00218: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0218\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0218/assets\n",
      "Epoch 219/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1582 - accuracy: 0.9353 - val_loss: 0.1425 - val_accuracy: 0.9464\n",
      "\n",
      "Epoch 00219: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0219\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0219/assets\n",
      "Epoch 220/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1589 - accuracy: 0.9353 - val_loss: 0.1418 - val_accuracy: 0.9456\n",
      "\n",
      "Epoch 00220: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0220\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0220/assets\n",
      "Epoch 221/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9353 - val_loss: 0.1417 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00221: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0221\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0221/assets\n",
      "Epoch 222/250\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9354 - val_loss: 0.1425 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00222: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0222\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0222/assets\n",
      "Epoch 223/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9354 - val_loss: 0.1415 - val_accuracy: 0.9461\n",
      "\n",
      "Epoch 00223: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0223\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0223/assets\n",
      "Epoch 224/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9352 - val_loss: 0.1412 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00224: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0224\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0224/assets\n",
      "Epoch 225/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9356 - val_loss: 0.1411 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00225: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0225\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0225/assets\n",
      "Epoch 226/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9354 - val_loss: 0.1423 - val_accuracy: 0.9472\n",
      "\n",
      "Epoch 00226: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0226\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0226/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9355 - val_loss: 0.1410 - val_accuracy: 0.9456\n",
      "\n",
      "Epoch 00227: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0227\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0227/assets\n",
      "Epoch 228/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9356 - val_loss: 0.1408 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00228: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0228\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0228/assets\n",
      "Epoch 229/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9357 - val_loss: 0.1408 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00229: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0229\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0229/assets\n",
      "Epoch 230/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9353 - val_loss: 0.1411 - val_accuracy: 0.9466\n",
      "\n",
      "Epoch 00230: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0230\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0230/assets\n",
      "Epoch 231/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9356 - val_loss: 0.1406 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00231: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0231\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0231/assets\n",
      "Epoch 232/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9360 - val_loss: 0.1404 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00232: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0232\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0232/assets\n",
      "Epoch 233/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9360 - val_loss: 0.1403 - val_accuracy: 0.9455\n",
      "\n",
      "Epoch 00233: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0233\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0233/assets\n",
      "Epoch 234/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1565 - accuracy: 0.9359 - val_loss: 0.1400 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00234: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0234\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0234/assets\n",
      "Epoch 235/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9357 - val_loss: 0.1402 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00235: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0235\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0235/assets\n",
      "Epoch 236/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9360 - val_loss: 0.1402 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00236: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0236\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0236/assets\n",
      "Epoch 237/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9358 - val_loss: 0.1400 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00237: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0237\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0237/assets\n",
      "Epoch 238/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9357 - val_loss: 0.1399 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00238: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0238\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0238/assets\n",
      "Epoch 239/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9360 - val_loss: 0.1403 - val_accuracy: 0.9464\n",
      "\n",
      "Epoch 00239: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0239\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0239/assets\n",
      "Epoch 240/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9360 - val_loss: 0.1396 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00240: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0240\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0240/assets\n",
      "Epoch 241/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9364 - val_loss: 0.1398 - val_accuracy: 0.9466\n",
      "\n",
      "Epoch 00241: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0241\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0241/assets\n",
      "Epoch 242/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9364 - val_loss: 0.1396 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00242: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0242\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0242/assets\n",
      "Epoch 243/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9361 - val_loss: 0.1393 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00243: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0243\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0243/assets\n",
      "Epoch 244/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9365 - val_loss: 0.1397 - val_accuracy: 0.9461\n",
      "\n",
      "Epoch 00244: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0244\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0244/assets\n",
      "Epoch 245/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9364 - val_loss: 0.1396 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00245: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0245\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0245/assets\n",
      "Epoch 246/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9355 - val_loss: 0.1392 - val_accuracy: 0.9459\n",
      "\n",
      "Epoch 00246: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0246\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0246/assets\n",
      "Epoch 247/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9362 - val_loss: 0.1393 - val_accuracy: 0.9463\n",
      "\n",
      "Epoch 00247: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0247\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0247/assets\n",
      "Epoch 248/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9360 - val_loss: 0.1395 - val_accuracy: 0.9467\n",
      "\n",
      "Epoch 00248: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0248\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0248/assets\n",
      "Epoch 249/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9362 - val_loss: 0.1390 - val_accuracy: 0.9453\n",
      "\n",
      "Epoch 00249: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0249\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0249/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/250\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9364 - val_loss: 0.1390 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00250: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0250\n",
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/E-0250/assets\n",
      "Training for 250 epochs & a batch size of 20480 took :\n",
      " 186.9399709701538 seconds\n"
     ]
    }
   ],
   "source": [
    "mlp = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(1, NUM_OF_CHANNELS)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dense(256, activation='sigmoid'),\n",
    "#   tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "reset_seeds(K)\n",
    "EPOCHS = 250\n",
    "BATCH_SIZE = 5*(64**2)\n",
    "\n",
    "\n",
    "out = f'/data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/MLP_ReLu/'\n",
    "\n",
    "mlp.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "            loss =  tf.keras.losses.binary_crossentropy,\n",
    "#             loss ='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join(out, 'E-{epoch:04d}')\n",
    "print(f'\\n {checkpoint_path} \\n')\n",
    "mlp.save_weights(checkpoint_path.format(epoch=0))\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,verbose=1,save_freq='epoch')\n",
    "\n",
    "start = time.time()\n",
    "model_history = mlp.fit(train_rad_flat, train_labels_1hot,\n",
    "                        validation_data=(valid_rad_flat,valid_labels_1hot),\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        callbacks=[cp_callback], \n",
    "                        epochs=EPOCHS, \n",
    "                        shuffle=True)\n",
    "end = time.time()\n",
    "print(f'Training for {EPOCHS} epochs & a batch size of {BATCH_SIZE} took :\\n {end-start} seconds')\n",
    "\n",
    "os.makedirs(name=f'{out}history',exist_ok=True)\n",
    "s = f'{out}/history/hist'\n",
    "\n",
    "\n",
    "with open(s, 'wb') as file_pi:\n",
    "    pickle.dump(model_history.history, file_pi)\n",
    "\n",
    "# 4vis = 1 2 3 4\n",
    "# vis+IR = 1234\n",
    "\n",
    "# remeber to save output of the training metricskeras.utils.plot_model(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(s, \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)\n",
    "accs = history['accuracy']\n",
    "val_accs = history['val_accuracy']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accs, color='red', label='acc')\n",
    "plt.plot(val_accs, color='blue', label='val acc')\n",
    "\n",
    "plt.ylim((.5,1.))\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Acc. v.s. Epoch')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss, color='red', label='loss')\n",
    "plt.plot(val_loss, color='blue', label='val_loss')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Loss v.s. Epoch')\n",
    "# plt.savefig('/data/keeling/a/jdnied2/c/MS_THESIS/Models/Plots/MLPS_batch_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b19212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 15:09:17.214338: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-05-21 15:09:17.214942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599820000 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 64, 64, 9), found shape=(32, 11)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mlp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/E-0250/\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                  \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_rad_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart)\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1629\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1628\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 1629\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1631\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /data/keeling/a/jdnied2/miniconda3/envs/TF_RF_GPU/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model: expected shape=(None, 64, 64, 9), found shape=(32, 11)\n"
     ]
    }
   ],
   "source": [
    "mlp = tf.keras.models.load_model(f'{out}/E-0250/', \n",
    "                                 compile=True)\n",
    "start = time.time()\n",
    "output = mlp.predict(test_rad_flat)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b374e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = np.zeros((2,2))\n",
    "\n",
    "@jit(nopython=True)                         \n",
    "def CM_G_flat(predictions, truth, CM):\n",
    "    ML_layer_0=predictions[:,0]\n",
    "    ML_layer_1=predictions[:,1]\n",
    " \n",
    "    for i in range(predictions.shape[0]):\n",
    "        if predictions[i,0] > predictions[i,1]:\n",
    "                p = 0\n",
    "        else:\n",
    "                p = 1\n",
    "                \n",
    "        if truth[i,0] > truth[i,1]:\n",
    "                t = 0\n",
    "        else:\n",
    "                t = 1\n",
    "        CM[p,t] += 1\n",
    "    return CM\n",
    "\n",
    "CM = CM_G_flat(output, test_labels_1hot, CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68deb57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46.41601562,  3.83398438],\n",
       "       [ 4.12695312, 45.62304688]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM/output.shape[0] *100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53d4c9",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f444f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_simple(input_size=(IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), \n",
    "               n_filters=64, n_classes=2):\n",
    "    inputs = Input(input_size)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n",
    "    conv = Conv2D(n_filters*2, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    conv = Conv2D(n_filters*4, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    conv = Conv2D(n_filters*8, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    conv = Conv2D(n_classes,\n",
    "                 1,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    conv_out = Activation('softmax')(conv)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv_out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d491a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_block(inputs=None, n_kernels=32, k_size=3, \n",
    "               dropout_prob=0, add_max_pooling=True):\n",
    "    \n",
    "    conv = Conv2D(n_kernels, \n",
    "                  kernel_size = k_size,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n",
    "    \n",
    "    conv = Conv2D(n_kernels, \n",
    "                  kernel_size = k_size, \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "   \n",
    "    \n",
    "\n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "        \n",
    "    if add_max_pooling:\n",
    "        next_layer = MaxPooling2D(pool_size=(2,2))(conv)      \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    #conv = BatchNormalization()(conv)\n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06d5846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block(expansive_input, concat_input, n_kernels=32, k_size=3):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_kernels,  \n",
    "                 kernel_size = 3,\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(expansive_input)\n",
    "    \n",
    "    merge = concatenate([up, concat_input], axis=3)\n",
    "    conv = Conv2D(n_kernels,  \n",
    "                 kernel_size = k_size,   \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n",
    "    conv = Conv2D(n_kernels,  \n",
    "                 kernel_size = k_size,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a207a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_block_attent(expansive_input, concat_input, n_kernels=32, k_size=3):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_kernels,  \n",
    "                 kernel_size = 3,\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(expansive_input)\n",
    "    attent = AttentionBlock(n_kernels)(concat_input,up)\n",
    "    merge = concatenate([up, attent], axis=3)\n",
    "    conv = Conv2D(n_kernels,  \n",
    "                 kernel_size = k_size,   \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n",
    "    conv = Conv2D(n_kernels,  \n",
    "                 kernel_size = k_size,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60c7cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), \n",
    "               n_kernels=32, n_classes=4):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoding (contract) path\n",
    "    cblock1 = down_block(inputs,       n_kernels)\n",
    "    cblock2 = down_block(cblock1[0], 2*n_kernels)\n",
    "    cblock3 = down_block(cblock2[0], 4*n_kernels)\n",
    "    cblock4 = down_block(cblock3[0], 8*n_kernels, dropout_prob=0.2) \n",
    "    cblock5 = down_block(cblock4[0],16*n_kernels, dropout_prob=0.2, add_max_pooling=None)     \n",
    "    \n",
    "    # Decoding (expand) path\n",
    "    ublock6 = up_block(cblock5[0], cblock4[1], 8*n_kernels)\n",
    "    ublock7 = up_block(ublock6,    cblock3[1], 4*n_kernels)\n",
    "    ublock8 = up_block(ublock7,    cblock2[1], 2*n_kernels)\n",
    "    ublock9 = up_block(ublock8,    cblock1[1],   n_kernels)\n",
    "\n",
    "    conv9 = Conv2D(n_classes,\n",
    "                 1,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "    \n",
    "    conv10 = Conv2D(n_classes, kernel_size=1, padding='same', activation = 'softmax')(conv9) \n",
    "    conv10 = Activation('softmax')(conv9)\n",
    "\n",
    "    unet = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b08c3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model_attent(input_size=(IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), \n",
    "               n_kernels=32, n_classes=4):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoding (contract) path\n",
    "    cblock1 = down_block(inputs,       n_kernels)\n",
    "    cblock2 = down_block(cblock1[0], 2*n_kernels)\n",
    "    cblock3 = down_block(cblock2[0], 4*n_kernels)\n",
    "    cblock4 = down_block(cblock3[0], 8*n_kernels, dropout_prob=0.2) \n",
    "    cblock5 = down_block(cblock4[0],16*n_kernels, dropout_prob=0.2, add_max_pooling=None)     \n",
    "    \n",
    "    # Decoding (expand) path\n",
    "    ublock6 = up_block_attent(cblock5[0], cblock4[1], 8*n_kernels)\n",
    "    ublock7 = up_block_attent(ublock6,    cblock3[1], 4*n_kernels)\n",
    "    ublock8 = up_block_attent(ublock7,    cblock2[1], 2*n_kernels)\n",
    "    ublock9 = up_block_attent(ublock8,    cblock1[1],   n_kernels)\n",
    "\n",
    "    conv9 = Conv2D(n_classes,\n",
    "                 1,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "    \n",
    "    conv10 = Conv2D(n_classes, kernel_size=1, padding='same', activation = 'softmax')(conv9) \n",
    "    conv10 = Activation('softmax')(conv9)\n",
    "\n",
    "    unet = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40d3f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class AttentionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(AttentionBlock, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.theta = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')\n",
    "        self.phi = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')\n",
    "        self.g = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')\n",
    "        self.psi = tf.keras.layers.Conv2D(1, kernel_size=1, strides=1, padding='same')\n",
    "        self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x, g):\n",
    "        theta_x = self.theta(x)\n",
    "        phi_g = self.phi(g)\n",
    "        concat_xg = tf.keras.layers.Add()([theta_x, phi_g])\n",
    "        concat_xg = tf.keras.layers.Activation('relu')(concat_xg)\n",
    "        psi = self.psi(concat_xg)\n",
    "        psi = self.sigmoid(psi)\n",
    "        return tf.keras.layers.Multiply()([x, psi])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1410a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_lab(input_size=(IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), \n",
    "               n_kernels=32, n_classes=2):\n",
    "    inputs = Input(input_size)\n",
    "    conv = tf.keras.layers.Conv2D(filters=256,\n",
    "                             kernel_size=(3, 3),\n",
    "                             dilation_rate=(6, 6),\n",
    "                             padding='same')(inputs)\n",
    "    conv = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=256,\n",
    "                                                 kernel_size=(1, 1),\n",
    "                                                 padding='same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(filters=256,\n",
    "                                                 kernel_size=(3, 3),\n",
    "                                                 dilation_rate=(6, 6),\n",
    "                                                 padding='same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(filters=256,\n",
    "                                                 kernel_size=(3, 3),\n",
    "                                                 dilation_rate=(12, 12),\n",
    "                                                 padding='same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2D(filters=256,\n",
    "                                                 kernel_size=(3, 3),\n",
    "                                                 dilation_rate=(18, 18),\n",
    "                                                 padding='same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Reshape((1, 1, 256)),\n",
    "            tf.keras.layers.Conv2D(filters=256,\n",
    "                                                 kernel_size=(1, 1),\n",
    "                                                 padding='same'),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.UpSampling2D(size=(IMG_DIM, IMG_DIM))\n",
    "        ])(conv)\n",
    "    spec_features = tf.keras.Sequential([\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(units=256),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Reshape((1, 1, 256))\n",
    "        ])(inputs)\n",
    "    conv = conv + spec_features\n",
    "    out = tf.keras.layers.Conv2D(filters=n_classes,\n",
    "                                                 kernel_size=(1, 1),\n",
    "                                                 padding='same')(conv)\n",
    "    dl = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abbc5fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 64, 64, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 64, 64, 32)   2624        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 64, 64, 32)   9248        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 32, 32, 32)   0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 32, 32, 64)   18496       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 32, 32, 64)   36928       conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 16, 16, 64)   0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 128)  73856       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 128)  147584      conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 8, 8, 128)    0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 256)    295168      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 256)    0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 4, 4, 256)    0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 512)    1180160     max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 512)    2359808     conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4, 4, 512)    0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 8, 8, 256)    1179904     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 512)    0           conv2d_transpose_10[0][0]        \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 256)    1179904     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 16, 16, 128)  295040      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 256)  0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 128)  295040      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 128)  147584      conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 32, 32, 64)   73792       conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 128)  0           conv2d_transpose_12[0][0]        \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 32, 32, 64)   73792       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 64, 64, 32)   18464       conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64, 64, 64)   0           conv2d_transpose_13[0][0]        \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 32)   18464       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 32)   9248        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 2)    66          conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 2)    0           conv2d_112[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 8,632,258\n",
      "Trainable params: 8,632,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = unet_model_attent((IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), n_classes=2)\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afdb22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KERAS AND TENSORFLOW GRAPHS RESET\n",
      "RANDOM SEEDS RESET\n",
      "\n",
      " /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-{epoch:04d} \n",
      "\n",
      "Epoch 1/250\n",
      "70/70 [==============================] - 67s 25ms/step - loss: 0.6861 - accuracy: 0.5061 - val_loss: 0.6244 - val_accuracy: 0.4556\n",
      "\n",
      "Epoch 00001: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0001\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.5952 - accuracy: 0.5931 - val_loss: 0.6119 - val_accuracy: 0.7582\n",
      "\n",
      "Epoch 00002: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0002\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0002/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.5530 - accuracy: 0.8148 - val_loss: 0.5438 - val_accuracy: 0.8271\n",
      "\n",
      "Epoch 00003: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0003\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0003/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0003/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.5331 - accuracy: 0.8314 - val_loss: 0.5241 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00004: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0004\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0004/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0004/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.5345 - accuracy: 0.8269 - val_loss: 0.5120 - val_accuracy: 0.8623\n",
      "\n",
      "Epoch 00005: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0005\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0005/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0005/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.5150 - accuracy: 0.8513 - val_loss: 0.5077 - val_accuracy: 0.8704\n",
      "\n",
      "Epoch 00006: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0006\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0006/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0006/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4991 - accuracy: 0.8709 - val_loss: 0.4940 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00007: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0007\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0007/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0007/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5113 - accuracy: 0.8571 - val_loss: 0.4974 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00008: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0008\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0008/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0008/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4960 - accuracy: 0.8688 - val_loss: 0.4906 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00009: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0009\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0009/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0009/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.5050 - accuracy: 0.8583 - val_loss: 0.4807 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00010: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0010\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0010/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0010/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4880 - accuracy: 0.8806 - val_loss: 0.4900 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00011: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0011\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0011/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0011/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4939 - accuracy: 0.8727 - val_loss: 0.4778 - val_accuracy: 0.8937\n",
      "\n",
      "Epoch 00012: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0012\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0012/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0012/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4895 - accuracy: 0.8752 - val_loss: 0.4730 - val_accuracy: 0.8953\n",
      "\n",
      "Epoch 00013: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0013\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0013/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0013/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4737 - accuracy: 0.8898 - val_loss: 0.4676 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00014: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0014\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0014/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0014/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4776 - accuracy: 0.8840 - val_loss: 0.4718 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00015: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0015\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0015/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0015/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4819 - accuracy: 0.8816 - val_loss: 0.4626 - val_accuracy: 0.9025\n",
      "\n",
      "Epoch 00016: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0016\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0016/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0016/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4746 - accuracy: 0.8876 - val_loss: 0.4695 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00017: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0017\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0017/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0017/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4708 - accuracy: 0.8944 - val_loss: 0.5023 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00018: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0018\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0018/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0018/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4700 - accuracy: 0.8931 - val_loss: 0.4621 - val_accuracy: 0.9033\n",
      "\n",
      "Epoch 00019: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0019\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0019/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0019/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4637 - accuracy: 0.9007 - val_loss: 0.4637 - val_accuracy: 0.9034\n",
      "\n",
      "Epoch 00020: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0020\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0020/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0020/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4658 - accuracy: 0.8954 - val_loss: 0.4557 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00021: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0021\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0021/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0021/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4568 - accuracy: 0.9060 - val_loss: 0.4553 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00022: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0022\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0022/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0022/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4509 - accuracy: 0.9109 - val_loss: 0.4554 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00023: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0023\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0023/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0023/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4551 - accuracy: 0.9064 - val_loss: 0.4524 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00024: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0024\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0024/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0024/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4476 - accuracy: 0.9139 - val_loss: 0.4602 - val_accuracy: 0.9024\n",
      "\n",
      "Epoch 00025: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0025\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0025/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0025/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4493 - accuracy: 0.9146 - val_loss: 0.4522 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00026: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0026\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0026/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0026/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4431 - accuracy: 0.9184 - val_loss: 0.4686 - val_accuracy: 0.8948\n",
      "\n",
      "Epoch 00027: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0027\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0027/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0027/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4463 - accuracy: 0.9154 - val_loss: 0.4481 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00028: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0028\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0028/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0028/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4387 - accuracy: 0.9210 - val_loss: 0.4496 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00029: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0029\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0029/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0029/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4359 - accuracy: 0.9229 - val_loss: 0.4480 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00030: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0030\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0030/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0030/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4333 - accuracy: 0.9264 - val_loss: 0.4462 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00031: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0031\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0031/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0031/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4310 - accuracy: 0.9270 - val_loss: 0.4468 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00032: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0032\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0032/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0032/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4308 - accuracy: 0.9282 - val_loss: 0.4484 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00033: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0033\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0033/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0033/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4433 - accuracy: 0.9181 - val_loss: 0.4488 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00034: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0034\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0034/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0034/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4266 - accuracy: 0.9319 - val_loss: 0.4451 - val_accuracy: 0.9169\n",
      "\n",
      "Epoch 00035: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0035\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0035/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0035/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4304 - accuracy: 0.9283 - val_loss: 0.4444 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00036: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0036\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0036/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0036/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4324 - accuracy: 0.9262 - val_loss: 0.4474 - val_accuracy: 0.9132\n",
      "\n",
      "Epoch 00037: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0037\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0037/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0037/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4303 - accuracy: 0.9279 - val_loss: 0.4445 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00038: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0038\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0038/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0038/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4285 - accuracy: 0.9285 - val_loss: 0.4568 - val_accuracy: 0.9136\n",
      "\n",
      "Epoch 00039: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0039\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0039/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0039/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4296 - accuracy: 0.9291 - val_loss: 0.4427 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00040: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0040\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0040/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0040/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4245 - accuracy: 0.9323 - val_loss: 0.4453 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00041: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0041\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0041/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0041/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/250\n",
      "70/70 [==============================] - 1s 21ms/step - loss: 0.4230 - accuracy: 0.9338 - val_loss: 0.4426 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00042: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0042\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0042/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0042/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4206 - accuracy: 0.9357 - val_loss: 0.4458 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00043: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0043\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0043/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0043/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4120 - accuracy: 0.9435 - val_loss: 0.4448 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00044: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0044\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0044/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0044/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4179 - accuracy: 0.9380 - val_loss: 0.4443 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00045: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0045\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0045/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0045/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4170 - accuracy: 0.9400 - val_loss: 0.4422 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00046: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0046\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0046/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0046/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4121 - accuracy: 0.9434 - val_loss: 0.4432 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00047: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0047\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0047/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0047/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4133 - accuracy: 0.9425 - val_loss: 0.4444 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00048: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0048\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0048/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0048/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4163 - accuracy: 0.9395 - val_loss: 0.4446 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00049: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0049\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0049/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0049/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4125 - accuracy: 0.9431 - val_loss: 0.4451 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00050: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0050\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0050/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0050/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4151 - accuracy: 0.9407 - val_loss: 0.4459 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00051: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0051\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0051/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0051/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4144 - accuracy: 0.9415 - val_loss: 0.4430 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00052: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0052\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0052/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0052/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4156 - accuracy: 0.9402 - val_loss: 0.4549 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00053: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0053\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0053/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0053/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4120 - accuracy: 0.9437 - val_loss: 0.4527 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00054: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0054\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0054/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0054/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4095 - accuracy: 0.9461 - val_loss: 0.4438 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00055: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0055\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0055/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0055/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4045 - accuracy: 0.9505 - val_loss: 0.4448 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00056: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0056\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0056/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0056/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4047 - accuracy: 0.9501 - val_loss: 0.4449 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00057: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0057\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0057/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0057/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4022 - accuracy: 0.9525 - val_loss: 0.4565 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00058: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0058\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0058/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0058/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4117 - accuracy: 0.9441 - val_loss: 0.4592 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00059: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0059\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0059/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0059/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4063 - accuracy: 0.9491 - val_loss: 0.4434 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00060: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0060\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0060/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0060/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3999 - accuracy: 0.9548 - val_loss: 0.4545 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00061: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0061\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0061/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0061/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4016 - accuracy: 0.9533 - val_loss: 0.4464 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00062: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0062\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0062/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0062/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3982 - accuracy: 0.9562 - val_loss: 0.4522 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00063: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0063\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0063/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0063/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3973 - accuracy: 0.9574 - val_loss: 0.4464 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00064: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0064\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0064/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0064/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3969 - accuracy: 0.9577 - val_loss: 0.4485 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00065: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0065\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0065/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0065/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3983 - accuracy: 0.9567 - val_loss: 0.4586 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00066: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0066\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0066/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0066/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4031 - accuracy: 0.9522 - val_loss: 0.4510 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00067: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0067\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0067/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0067/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3923 - accuracy: 0.9621 - val_loss: 0.4534 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00068: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0068\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0068/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0068/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3922 - accuracy: 0.9617 - val_loss: 0.4541 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00069: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0069\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0069/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0069/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3923 - accuracy: 0.9616 - val_loss: 0.4509 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00070: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0070\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0070/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0070/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3918 - accuracy: 0.9625 - val_loss: 0.4595 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00071: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0071\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0071/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0071/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3938 - accuracy: 0.9611 - val_loss: 0.4519 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00072: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0072\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0072/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0072/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3910 - accuracy: 0.9633 - val_loss: 0.4571 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00073: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0073\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0073/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0073/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3877 - accuracy: 0.9659 - val_loss: 0.4558 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00074: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0074\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0074/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0074/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3895 - accuracy: 0.9646 - val_loss: 0.4555 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00075: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0075\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0075/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0075/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3905 - accuracy: 0.9638 - val_loss: 0.4597 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00076: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0076\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0076/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0076/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3844 - accuracy: 0.9691 - val_loss: 0.4606 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00077: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0077\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0077/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0077/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3850 - accuracy: 0.9688 - val_loss: 0.4627 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00078: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0078\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0078/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0078/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3851 - accuracy: 0.9686 - val_loss: 0.4601 - val_accuracy: 0.9213\n",
      "\n",
      "Epoch 00079: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0079\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0079/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0079/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3873 - accuracy: 0.9668 - val_loss: 0.4589 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00080: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0080\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0080/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0080/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3795 - accuracy: 0.9736 - val_loss: 0.4675 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00081: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0081\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0081/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0081/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3802 - accuracy: 0.9732 - val_loss: 0.4701 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00082: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0082\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0082/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0082/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3778 - accuracy: 0.9754 - val_loss: 0.4706 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00083: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0083\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0083/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0083/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3820 - accuracy: 0.9715 - val_loss: 0.4713 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00084: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0084\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0084/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0084/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3774 - accuracy: 0.9758 - val_loss: 0.4744 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00085: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0085\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0085/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0085/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3763 - accuracy: 0.9765 - val_loss: 0.4704 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00086: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0086\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0086/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0086/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3797 - accuracy: 0.9736 - val_loss: 0.4744 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00087: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0087\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0087/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0087/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3782 - accuracy: 0.9749 - val_loss: 0.4713 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00088: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0088\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0088/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0088/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3733 - accuracy: 0.9793 - val_loss: 0.4872 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00089: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0089\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0089/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0089/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3733 - accuracy: 0.9792 - val_loss: 0.4825 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00090: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0090\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0090/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0090/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3742 - accuracy: 0.9783 - val_loss: 0.4786 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00091: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0091\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0091/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0091/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3692 - accuracy: 0.9826 - val_loss: 0.4865 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00092: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0092\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0092/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0092/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3721 - accuracy: 0.9800 - val_loss: 0.4814 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00093: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0093\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0093/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0093/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3727 - accuracy: 0.9796 - val_loss: 0.4968 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00094: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0094\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0094/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0094/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3721 - accuracy: 0.9798 - val_loss: 0.5014 - val_accuracy: 0.9176\n",
      "\n",
      "Epoch 00095: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0095\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0095/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0095/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3754 - accuracy: 0.9770 - val_loss: 0.4795 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00096: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0096\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0096/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0096/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3710 - accuracy: 0.9813 - val_loss: 0.4896 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00097: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0097\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0097/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0097/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/250\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3671 - accuracy: 0.9846 - val_loss: 0.4904 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00098: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0098\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0098/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0098/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3661 - accuracy: 0.9853 - val_loss: 0.4979 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00099: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0099\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0099/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0099/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3682 - accuracy: 0.9835 - val_loss: 0.4922 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00100: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0100\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0100/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0100/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3660 - accuracy: 0.9854 - val_loss: 0.5025 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00101: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0101\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0101/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0101/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3677 - accuracy: 0.9839 - val_loss: 0.4909 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00102: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0102\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0102/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0102/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3645 - accuracy: 0.9862 - val_loss: 0.4966 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00103: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0103\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0103/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0103/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3646 - accuracy: 0.9866 - val_loss: 0.5060 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00104: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0104\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0104/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0104/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3644 - accuracy: 0.9870 - val_loss: 0.5032 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00105: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0105\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0105/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0105/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3649 - accuracy: 0.9863 - val_loss: 0.5066 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00106: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0106\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0106/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0106/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3619 - accuracy: 0.9889 - val_loss: 0.5060 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00107: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0107\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0107/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0107/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3630 - accuracy: 0.9880 - val_loss: 0.5177 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00108: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0108\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0108/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0108/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3610 - accuracy: 0.9895 - val_loss: 0.5163 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00109: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0109\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0109/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0109/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3614 - accuracy: 0.9894 - val_loss: 0.5136 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00110: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0110\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0110/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0110/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3627 - accuracy: 0.9882 - val_loss: 0.5272 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00111: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0111\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0111/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0111/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3606 - accuracy: 0.9900 - val_loss: 0.5232 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00112: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0112\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0112/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0112/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/250\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3600 - accuracy: 0.9904 - val_loss: 0.5283 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00113: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0113\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0113/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0113/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3599 - accuracy: 0.9905 - val_loss: 0.5317 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00114: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0114\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0114/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0114/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3613 - accuracy: 0.9891 - val_loss: 0.5142 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00115: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0115\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0115/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0115/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3641 - accuracy: 0.9866 - val_loss: 0.5186 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00116: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0116\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0116/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0116/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3638 - accuracy: 0.9869 - val_loss: 0.5095 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00117: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0117\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0117/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0117/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3626 - accuracy: 0.9879 - val_loss: 0.5292 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00118: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0118\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0118/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0118/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3613 - accuracy: 0.9892 - val_loss: 0.5419 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00119: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0119\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0119/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0119/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3575 - accuracy: 0.9923 - val_loss: 0.5334 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00120: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0120\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0120/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0120/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3567 - accuracy: 0.9930 - val_loss: 0.5439 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00121: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0121\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0121/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0121/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3554 - accuracy: 0.9941 - val_loss: 0.5402 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00122: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0122\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0122/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0122/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3558 - accuracy: 0.9937 - val_loss: 0.5457 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00123: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0123\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0123/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0123/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3557 - accuracy: 0.9938 - val_loss: 0.5370 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00124: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0124\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0124/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0124/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/250\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.3552 - accuracy: 0.9941 - val_loss: 0.5494 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00125: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0125\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0125/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0125/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3902 - accuracy: 0.9653 - val_loss: 0.4606 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00126: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0126\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0126/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0126/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3909 - accuracy: 0.9605 - val_loss: 0.4930 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00127: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0127\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0127/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0127/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3605 - accuracy: 0.9900 - val_loss: 0.5180 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00128: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0128\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0128/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0128/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3559 - accuracy: 0.9940 - val_loss: 0.5292 - val_accuracy: 0.9190\n",
      "\n",
      "Epoch 00129: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0129\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0129/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0129/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3547 - accuracy: 0.9949 - val_loss: 0.5459 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00130: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0130\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0130/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0130/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3542 - accuracy: 0.9953 - val_loss: 0.5531 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00131: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0131\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0131/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0131/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3533 - accuracy: 0.9959 - val_loss: 0.5562 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00132: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0132\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0132/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0132/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3533 - accuracy: 0.9959 - val_loss: 0.5633 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00133: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0133\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0133/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0133/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3525 - accuracy: 0.9964 - val_loss: 0.5689 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00134: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0134\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0134/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0134/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3527 - accuracy: 0.9962 - val_loss: 0.5756 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00135: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0135\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0135/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0135/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.9964 - val_loss: 0.5710 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00136: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0136\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0136/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0136/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3519 - accuracy: 0.9967 - val_loss: 0.5937 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00137: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0137\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0137/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0137/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3536 - accuracy: 0.9954 - val_loss: 0.5658 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00138: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0138\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0138/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0138/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3529 - accuracy: 0.9958 - val_loss: 0.5798 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00139: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0139\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0139/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0139/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3552 - accuracy: 0.9939 - val_loss: 0.5660 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00140: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0140\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0140/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0140/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3527 - accuracy: 0.9960 - val_loss: 0.5679 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00141: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0141\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0141/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0141/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3526 - accuracy: 0.9961 - val_loss: 0.5755 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00142: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0142\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0142/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0142/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3517 - accuracy: 0.9969 - val_loss: 0.5833 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00143: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0143\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0143/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0143/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3521 - accuracy: 0.9965 - val_loss: 0.5862 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00144: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0144\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0144/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0144/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3518 - accuracy: 0.9966 - val_loss: 0.5790 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00145: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0145\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0145/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0145/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3518 - accuracy: 0.9967 - val_loss: 0.5957 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00146: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0146\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0146/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0146/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3512 - accuracy: 0.9972 - val_loss: 0.5912 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00147: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0147\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0147/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0147/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3509 - accuracy: 0.9974 - val_loss: 0.5959 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00148: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0148\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0148/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0148/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3511 - accuracy: 0.9972 - val_loss: 0.5966 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00149: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0149\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0149/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0149/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3508 - accuracy: 0.9974 - val_loss: 0.5963 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00150: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0150\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0150/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0150/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3505 - accuracy: 0.9976 - val_loss: 0.5995 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00151: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0151\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0151/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0151/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3503 - accuracy: 0.9978 - val_loss: 0.6058 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00152: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0152\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0152/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0152/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3510 - accuracy: 0.9972 - val_loss: 0.6048 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00153: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0153\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0153/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0153/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3506 - accuracy: 0.9975 - val_loss: 0.5955 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00154: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0154\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0154/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0154/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.9961 - val_loss: 0.6080 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00155: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0155\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0155/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0155/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3511 - accuracy: 0.9971 - val_loss: 0.5881 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00156: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0156\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0156/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0156/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3549 - accuracy: 0.9939 - val_loss: 0.5814 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00157: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0157\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0157/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0157/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3535 - accuracy: 0.9953 - val_loss: 0.5481 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00158: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0158\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0158/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0158/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3562 - accuracy: 0.9929 - val_loss: 0.6158 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 00159: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0159\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0159/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0159/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3573 - accuracy: 0.9921 - val_loss: 0.5898 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00160: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0160\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0160/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0160/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3510 - accuracy: 0.9972 - val_loss: 0.5859 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00161: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0161\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0161/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0161/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3495 - accuracy: 0.9984 - val_loss: 0.6033 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00162: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0162\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0162/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0162/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3494 - accuracy: 0.9985 - val_loss: 0.6146 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00163: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0163\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0163/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0163/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3491 - accuracy: 0.9987 - val_loss: 0.6173 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00164: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0164\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0164/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0164/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3487 - accuracy: 0.9989 - val_loss: 0.6167 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00165: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0165\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0165/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0165/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3490 - accuracy: 0.9987 - val_loss: 0.6270 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00166: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0166\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0166/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0166/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3490 - accuracy: 0.9987 - val_loss: 0.6230 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00167: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0167\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0167/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0167/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3488 - accuracy: 0.9988 - val_loss: 0.6296 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00168: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0168\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0168/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0168/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3488 - accuracy: 0.9988 - val_loss: 0.6331 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00169: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0169\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0169/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0169/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3489 - accuracy: 0.9987 - val_loss: 0.6347 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00170: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0170\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0170/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0170/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3490 - accuracy: 0.9986 - val_loss: 0.6376 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00171: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0171\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0171/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0171/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3496 - accuracy: 0.9981 - val_loss: 0.6225 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00172: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0172\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0172/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0172/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3497 - accuracy: 0.9981 - val_loss: 0.6329 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00173: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0173\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0173/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0173/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3492 - accuracy: 0.9985 - val_loss: 0.6389 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00174: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0174\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0174/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0174/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3490 - accuracy: 0.9985 - val_loss: 0.6304 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00175: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0175\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0175/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0175/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3492 - accuracy: 0.9985 - val_loss: 0.6216 - val_accuracy: 0.9219\n",
      "\n",
      "Epoch 00176: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0176\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0176/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0176/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3494 - accuracy: 0.9983 - val_loss: 0.6423 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00177: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0177\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0177/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0177/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3492 - accuracy: 0.9984 - val_loss: 0.6398 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00178: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0178\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0178/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0178/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3493 - accuracy: 0.9983 - val_loss: 0.6431 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00179: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0179\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0179/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0179/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3499 - accuracy: 0.9978 - val_loss: 0.6364 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00180: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0180\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0180/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0180/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3492 - accuracy: 0.9983 - val_loss: 0.6475 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00181: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0181\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0181/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0181/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4055 - accuracy: 0.9458 - val_loss: 0.4606 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00182: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0182\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0182/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0182/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4031 - accuracy: 0.9543 - val_loss: 0.5157 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00183: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0183\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0183/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0183/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3575 - accuracy: 0.9922 - val_loss: 0.5504 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00184: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0184\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0184/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0184/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3509 - accuracy: 0.9975 - val_loss: 0.5793 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00185: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0185\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0185/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0185/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3493 - accuracy: 0.9986 - val_loss: 0.5882 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00186: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0186\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0186/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0186/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3487 - accuracy: 0.9990 - val_loss: 0.6017 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00187: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0187\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0187/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0187/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3485 - accuracy: 0.9992 - val_loss: 0.6088 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00188: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0188\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0188/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0188/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3483 - accuracy: 0.9992 - val_loss: 0.6168 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00189: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0189\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0189/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0189/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.9993 - val_loss: 0.6197 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00190: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0190\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0190/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0190/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3480 - accuracy: 0.9994 - val_loss: 0.6235 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00191: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0191\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0191/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0191/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3481 - accuracy: 0.9993 - val_loss: 0.6279 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00192: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0192\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0192/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0192/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6280 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00193: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0193\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0193/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0193/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3480 - accuracy: 0.9993 - val_loss: 0.6314 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00194: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0194\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0194/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0194/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3480 - accuracy: 0.9993 - val_loss: 0.6383 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00195: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0195\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0195/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0195/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6379 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00196: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0196\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0196/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0196/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6385 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00197: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0197\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0197/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0197/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3480 - accuracy: 0.9993 - val_loss: 0.6428 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00198: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0198\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0198/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0198/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6409 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00199: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0199\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0199/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0199/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3483 - accuracy: 0.9991 - val_loss: 0.6418 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00200: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0200\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0200/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0200/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3485 - accuracy: 0.9989 - val_loss: 0.6500 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00201: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0201\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0201/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0201/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3484 - accuracy: 0.9990 - val_loss: 0.6426 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00202: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0202\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0202/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0202/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3482 - accuracy: 0.9991 - val_loss: 0.6493 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00203: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0203\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0203/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0203/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.9991 - val_loss: 0.6415 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00204: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0204\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0204/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0204/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6438 - val_accuracy: 0.9224\n",
      "\n",
      "Epoch 00205: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0205\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0205/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0205/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3485 - accuracy: 0.9989 - val_loss: 0.6442 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00206: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0206\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0206/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0206/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3482 - accuracy: 0.9991 - val_loss: 0.6383 - val_accuracy: 0.9227\n",
      "\n",
      "Epoch 00207: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0207\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0207/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0207/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3485 - accuracy: 0.9989 - val_loss: 0.6391 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00208: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0208\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0208/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0208/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3499 - accuracy: 0.9978 - val_loss: 0.5957 - val_accuracy: 0.9121\n",
      "\n",
      "Epoch 00209: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0209\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0209/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0209/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3553 - accuracy: 0.9938 - val_loss: 0.5900 - val_accuracy: 0.9230\n",
      "\n",
      "Epoch 00210: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0210\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0210/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0210/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3520 - accuracy: 0.9962 - val_loss: 0.5818 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00211: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0211\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0211/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0211/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3524 - accuracy: 0.9957 - val_loss: 0.6141 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00212: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0212\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0212/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0212/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3493 - accuracy: 0.9983 - val_loss: 0.6190 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00213: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0213\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0213/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0213/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3480 - accuracy: 0.9992 - val_loss: 0.6416 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00214: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0214\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0214/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0214/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3476 - accuracy: 0.9995 - val_loss: 0.6326 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00215: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0215\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0215/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0215/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3481 - accuracy: 0.9992 - val_loss: 0.6492 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00216: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0216\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0216/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0216/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3475 - accuracy: 0.9995 - val_loss: 0.6480 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00217: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0217\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0217/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0217/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3474 - accuracy: 0.9996 - val_loss: 0.6544 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00218: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0218\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0218/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0218/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3475 - accuracy: 0.9996 - val_loss: 0.6525 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00219: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0219\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0219/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0219/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/250\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.3475 - accuracy: 0.9996 - val_loss: 0.6547 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00220: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0220\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0220/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0220/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3474 - accuracy: 0.9996 - val_loss: 0.6662 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00221: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0221\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0221/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0221/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3475 - accuracy: 0.9995 - val_loss: 0.6692 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00222: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0222\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0222/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0222/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3476 - accuracy: 0.9995 - val_loss: 0.6625 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00223: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0223\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0223/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0223/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3481 - accuracy: 0.9991 - val_loss: 0.6598 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00224: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0224\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0224/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0224/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3477 - accuracy: 0.9994 - val_loss: 0.6635 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00225: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0225\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0225/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0225/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3478 - accuracy: 0.9993 - val_loss: 0.6692 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00226: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0226\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0226/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0226/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3477 - accuracy: 0.9994 - val_loss: 0.6660 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00227: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0227\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0227/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0227/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3477 - accuracy: 0.9994 - val_loss: 0.6632 - val_accuracy: 0.9238\n",
      "\n",
      "Epoch 00228: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0228\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0228/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0228/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3477 - accuracy: 0.9994 - val_loss: 0.6556 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00229: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0229\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0229/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0229/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3478 - accuracy: 0.9993 - val_loss: 0.6622 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00230: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0230\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0230/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0230/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3483 - accuracy: 0.9990 - val_loss: 0.6557 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00231: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0231\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0231/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0231/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3957 - accuracy: 0.9523 - val_loss: 0.5028 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00232: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0232\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0232/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0232/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4948 - accuracy: 0.8534 - val_loss: 0.4656 - val_accuracy: 0.9111\n",
      "\n",
      "Epoch 00233: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0233\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0233/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0233/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4717 - accuracy: 0.8925 - val_loss: 0.4490 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00234: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0234\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0234/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0234/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4362 - accuracy: 0.9244 - val_loss: 0.4427 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00235: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0235\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0235/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0235/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.4054 - accuracy: 0.9498 - val_loss: 0.4616 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00236: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0236\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0236/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0236/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3866 - accuracy: 0.9670 - val_loss: 0.4799 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00237: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0237\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0237/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0237/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3682 - accuracy: 0.9834 - val_loss: 0.4929 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00238: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0238\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0238/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0238/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3578 - accuracy: 0.9922 - val_loss: 0.5227 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00239: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0239\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0239/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0239/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/250\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.3534 - accuracy: 0.9957 - val_loss: 0.5381 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00240: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0240\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0240/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0240/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3515 - accuracy: 0.9972 - val_loss: 0.5574 - val_accuracy: 0.9206\n",
      "\n",
      "Epoch 00241: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0241\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0241/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0241/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3503 - accuracy: 0.9981 - val_loss: 0.5632 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00242: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0242\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0242/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0242/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3501 - accuracy: 0.9982 - val_loss: 0.5812 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00243: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0243\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0243/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0243/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3491 - accuracy: 0.9988 - val_loss: 0.5938 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00244: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0244\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0244/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0244/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3486 - accuracy: 0.9991 - val_loss: 0.5968 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00245: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0245\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0245/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0245/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/250\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.3484 - accuracy: 0.9992 - val_loss: 0.6017 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00246: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0246\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0246/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0246/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.9994 - val_loss: 0.6082 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00247: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0247\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0247/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0247/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3482 - accuracy: 0.9994 - val_loss: 0.6140 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00248: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0248\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0248/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0248/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3479 - accuracy: 0.9995 - val_loss: 0.6231 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00249: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0249\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0249/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0249/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/250\n",
      "70/70 [==============================] - 1s 19ms/step - loss: 0.3480 - accuracy: 0.9994 - val_loss: 0.6296 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00250: saving model to /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0250\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2969cc790>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab28c128880>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab287618460>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x2ab2968074c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, conv2d_11_layer_call_fn, conv2d_11_layer_call_and_return_conditional_losses, conv2d_13_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0250/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/E-0250/assets\n"
     ]
    }
   ],
   "source": [
    "reset_seeds(K)\n",
    "\n",
    "out = f'/data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/U-Net-Attent/'\n",
    "\n",
    "EPOCHS = 250\n",
    "\n",
    "# cnn = unet_model((IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), n_classes=2)\n",
    "cnn = unet_model_attent((IMG_DIM, IMG_DIM, NUM_OF_CHANNELS), n_classes=2)\n",
    "\n",
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "            loss =  tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#             loss ='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint_path = os.path.join(out, 'E-{epoch:04d}')\n",
    "print(f'\\n {checkpoint_path} \\n')\n",
    "cnn.save_weights(checkpoint_path.format(epoch=0))\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,verbose=1,save_freq='epoch')\n",
    "\n",
    "model_history = cnn.fit(training_rad, tf.one_hot(training_cmask,2),\n",
    "                        validation_data=(validate_rad,tf.one_hot(validate_cmask,2)),\n",
    "                        batch_size=5, callbacks=[cp_callback], epochs=EPOCHS)\n",
    "\n",
    "os.makedirs(name=f'{out}history',exist_ok=True)\n",
    "s = f'{out}/history/hist'\n",
    "\n",
    "\n",
    "with open(s, 'wb') as file_pi:\n",
    "    pickle.dump(model_history.history, file_pi)\n",
    "# 4vis = 1 2 3 4\n",
    "# vis+IR = 1234\n",
    "\n",
    "# remeber to save output of the training metricskeras.utils.plot_model(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6c59f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss v.s. Epoch')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = f'/data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/DeepLab/'\n",
    "s = f'{out}/history/hist'\n",
    "\n",
    "with open(s, \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)\n",
    "accs = history['accuracy']\n",
    "val_accs = history['val_accuracy']\n",
    "loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accs, color='red', label='acc')\n",
    "plt.plot(val_accs, color='blue', label='val acc')\n",
    "\n",
    "plt.ylim((.5,1.))\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Acc. v.s. Epoch')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss, color='red', label='loss')\n",
    "plt.plot(val_loss, color='blue', label='val_loss')\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title('Loss v.s. Epoch')\n",
    "# plt.savefig('/data/keeling/a/jdnied2/c/MS_THESIS/Models/Plots/MLPS_batch_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aad7a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32689404487609863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 64, 64, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = f'/data/keeling/a/jdnied2/c/MS_THESIS/Models/Inner-Compare/DeepLab/'\n",
    "\n",
    "model = tf.keras.models.load_model(f'{out}/E-0250/', \n",
    "                                 compile=True)\n",
    "start = time.time()\n",
    "model_predictions = model.predict(testing_rad)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "model_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "906f0fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3a8446c1fb457eaa26df8080c26f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with GPU: 0.23119428474456072\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "@jit(nopython=True)                         \n",
    "def CM_G(predictions, masks, image_n):\n",
    "    ML_layer_0=predictions[image_n,:,:,0]\n",
    "    ML_layer_1=predictions[image_n,:,:,1]\n",
    "\n",
    "    x_axis_lim = IMG_DIM\n",
    "    y_axis_lim = IMG_DIM\n",
    "    \n",
    "    for x in range(x_axis_lim):\n",
    "        for y in range(y_axis_lim):\n",
    "            if ML_layer_0[x,y] > ML_layer_1[x,y]:\n",
    "                masks[image_n,x,y] = 0\n",
    "            else:\n",
    "                masks[image_n,x,y] = 1\n",
    "\n",
    "    \n",
    "    return masks\n",
    "\n",
    "start = timer()\n",
    "model_masks = np.zeros((np.shape(model_predictions)[0],IMG_DIM,IMG_DIM))\n",
    "for image_n in tqdm(range(len(model_predictions))):\n",
    "    masks=CM_G(model_predictions,model_masks,image_n)\n",
    "print(\"with GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f2dd8559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758134765625"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing_cmask[0]\n",
    "np.sum(masks[:]==testing_cmask[:])/(100*64**2\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "97033954",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)                         \n",
    "def confusion_matrix_generate(ML_mask, TRUTH_mask, CM_data):\n",
    "    for x in range(IMG_DIM):\n",
    "        for y in range(IMG_DIM):\n",
    "            ML_pixel = int(ML_mask[x,y])\n",
    "            TRUTH_pixel = int(TRUTH_mask[x,y])\n",
    "            CM_data[ML_pixel,TRUTH_pixel]+=1\n",
    "    return CM_data\n",
    "\n",
    "n_classes=2\n",
    "CM_data = np.zeros((2,2))\n",
    "total_pixels = 0\n",
    "for ML_mask, TRUTH_mask in zip(masks, testing_cmask):\n",
    "    CM_data = confusion_matrix_generate(ML_mask, TRUTH_mask, CM_data)\n",
    "    total_pixels+=IMG_DIM**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2b2c06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37678223, 0.11321777],\n",
       "       [0.12864746, 0.38135254]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(CM_data/total_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b74c8838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.67822266, 11.32177734],\n",
       "       [12.86474609, 38.13525391]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(CM_data/total_pixels)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd4110",
   "metadata": {},
   "source": [
    "# MISR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbfeea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = use_files[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "689f5504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(f'/data/gdi/c/gzhao1/joseph/rccm/{im_n}*{date}*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73b45eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Band_1.0', 'Band_2.0', 'Band_20.0', 'Band_26.0', 'Band_27.0', 'Band_29.0', 'Band_31.0', 'Band_32.0', 'Band_35.0']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f363402d640d4f93916e80db037d0aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 9, 64, 64)\n",
      "(400, 64, 64, 9)\n",
      "no\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     misr_cm[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[43mglob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/gdi/c/gzhao1/joseph/rccm/testing/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mim_n\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m*.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     11\u001b[0m misr_cm \u001b[38;5;241m=\u001b[39m make_binary(misr_cm \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m mod_cm \u001b[38;5;241m=\u001b[39m make_binary(mod_cm)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mod_rad, mod_cm = get_modis_data([1,2,20,26,27,29,31,32,35], np.array(filenames))\n",
    "misr_cm = np.zeros(np.shape(mod_cm))\n",
    "for i, f in enumerate(np.array(filenames)):\n",
    "    date = f.split('_')[-3]\n",
    "    im_n = f.split('+')[-1]\n",
    "    if len(glob.glob(f'/data/gdi/c/gzhao1/joseph/rccm/testing/{im_n}*{date}*.npy')) > 0:\n",
    "        print('yes')\n",
    "    else:\n",
    "        print('no')\n",
    "    misr_cm[i] = np.load(glob.glob(f'/data/gdi/c/gzhao1/joseph/rccm/testing/{im_n}*{date}*.npy')[0])\n",
    "misr_cm = make_binary(misr_cm - 1)\n",
    "mod_cm = make_binary(mod_cm)\n",
    "\n",
    "stats = []\n",
    "for i in range(100):\n",
    "    total_p = 0\n",
    "    success = 0\n",
    "    for x in range(64):\n",
    "        for y in range(64):\n",
    "            misr_p = misr_cm[i,x,y]\n",
    "            if misr_p != -1:\n",
    "                total_p += 1.\n",
    "                if misr_p == mod_cm[i,x,y]:\n",
    "                    success += 1.\n",
    "    stats.append(success/total_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8791da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b455f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'mod_rad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 39 perfect\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m ax[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mmod_rad\u001b[49m[i,:,:,\u001b[38;5;241m1\u001b[39m], vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m ax[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(mod_rad[i,:,:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m], vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8.0\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9.5\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray_r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m ax[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mimshow(misr_cm[i]\u001b[38;5;241m-\u001b[39mmod_cm[i], cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbwr_r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mod_rad' is not defined"
     ]
    }
   ],
   "source": [
    "# showing 10 and 42\n",
    "i=42 # 30 31 32 42\n",
    "# 39 perfect\n",
    "fig,ax = plt.subplots(2,3)\n",
    "ax[0,0].imshow(mod_rad[i,:,:,1], vmin=0, vmax=28, cmap='gray')\n",
    "ax[0,1].imshow(mod_rad[i,:,:,-3], vmin=8.0, vmax=9.5, cmap='gray_r')\n",
    "ax[0,2].imshow(misr_cm[i]-mod_cm[i], cmap = 'bwr_r')\n",
    "ax[1,0].imshow(misr_cm[i], cmap='gray_r')\n",
    "ax[1,1].imshow(mod_cm[i], cmap='gray_r')\n",
    "ax[1,2].imshow(masks[i], cmap='gray_r')\n",
    "\n",
    "ax[0,0].set_title(r'Band 2 - .86 $\\mu$m')\n",
    "ax[0,1].set_title(r'Band 31 - 11$\\mu$m')\n",
    "ax[0,2].set_title('MOD35-RCCM')\n",
    "ax[1,0].set_title('RCCM')\n",
    "ax[1,1].set_title('MOD35')\n",
    "ax[1,2].set_title('ML')\n",
    "\n",
    "\n",
    "for a in range(2):\n",
    "    for b in range(3):\n",
    "        ax[a,b].set_xticks([])\n",
    "        ax[a,b].set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be930018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox  6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute('tabindex', '0');\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;' +\n",
       "            'z-index: 2;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: relative;' +\n",
       "            'z-index: 0;'\n",
       "    );\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box;' +\n",
       "            'left: 0;' +\n",
       "            'pointer-events: none;' +\n",
       "            'position: absolute;' +\n",
       "            'top: 0;' +\n",
       "            'z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            /* This rescales the canvas back to display pixels, so that it\n",
       "             * appears correct on HiDPI screens. */\n",
       "            canvas.style.width = width + 'px';\n",
       "            canvas.style.height = height + 'px';\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        /* User Agent sniffing is bad, but WebKit is busted:\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
       "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
       "         * The worst that happens here is that they get an extra browser\n",
       "         * selection when dragging, if this check fails to catch them.\n",
       "         */\n",
       "        var UA = navigator.userAgent;\n",
       "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
       "        if(isWebKit) {\n",
       "            return function (event) {\n",
       "                /* This prevents the web browser from automatically changing to\n",
       "                 * the text insertion cursor when the button is pressed. We\n",
       "                 * want to control all of the cursor setting manually through\n",
       "                 * the 'cursor' event from matplotlib */\n",
       "                event.preventDefault()\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        } else {\n",
       "            return function (event) {\n",
       "                return fig.mouse_event(event, name);\n",
       "            };\n",
       "        }\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    canvas_div.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.canvas_div.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "function getModifiers(event) {\n",
       "    var mods = [];\n",
       "    if (event.ctrlKey) {\n",
       "        mods.push('ctrl');\n",
       "    }\n",
       "    if (event.altKey) {\n",
       "        mods.push('alt');\n",
       "    }\n",
       "    if (event.shiftKey) {\n",
       "        mods.push('shift');\n",
       "    }\n",
       "    if (event.metaKey) {\n",
       "        mods.push('meta');\n",
       "    }\n",
       "    return mods;\n",
       "}\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    // from https://stackoverflow.com/q/1114465\n",
       "    var boundingRect = this.canvas.getBoundingClientRect();\n",
       "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
       "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        modifiers: getModifiers(event),\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7944285750398139\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(stats)\n",
    "print((np.sum(mod_cm==misr_cm)-np.sum(misr_cm==-1))/((64*64*100)-np.sum(misr_cm==-1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_RF_GPU",
   "language": "python",
   "name": "tf_rf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
